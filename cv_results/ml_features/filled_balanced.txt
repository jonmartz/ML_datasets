AutoML progress: |
08:53:51.501: Fold column FOLD will be used for cross-validation. nfolds parameter will be ignored.
08:53:51.651: _train param, Dropping bad and constant columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]

█████████████████████████████████████████████████████████████
09:16:53.242: _train param, Dropping bad and constant columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]

█
09:35:58.506: _train param, Dropping bad and constant columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]

█
10:07:18.875: _train param, Dropping unused columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


10:07:31.887: _train param, Dropping bad and constant columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


10:34:47.163: _train param, Dropping bad and constant columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


10:49:46.333: _train param, Dropping bad and constant columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


11:08:23.571: _train param, Dropping bad and constant columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


11:28:16.841: _train param, Dropping bad and constant columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


11:52:07.108: _train param, Dropping unused columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


11:52:19.122: _train param, Dropping unused columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


11:52:34.133: _train param, Dropping bad and constant columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


12:05:41.364: _train param, Dropping bad and constant columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


12:22:33.554: _train param, Dropping bad and constant columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


12:37:41.766: _train param, Dropping bad and constant columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


12:44:45.849: _train param, Dropping unused columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


12:44:57.866: _train param, Dropping unused columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


14:18:43.148: _train param, Dropping unused columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


14:18:55.162: _train param, Dropping unused columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


14:54:40.534: _train param, Dropping unused columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


14:54:53.590: _train param, Dropping unused columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


14:55:14.630: _train param, Dropping unused columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


14:56:29.677: _train param, Dropping unused columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


14:57:30.722: _train param, Dropping unused columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


15:00:19.769: _train param, Dropping unused columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


15:02:10.811: _train param, Dropping unused columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


15:04:11.844: _train param, Dropping unused columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]

| (done) 100%
Model Details
=============
H2OGradientBoostingEstimator :  Gradient Boosting Machine
Model Key:  GBM_grid_1_AutoML_1_20220101_85351_model_2


Model Summary:
number_of_trees	number_of_internal_trees	model_size_in_bytes	min_depth	max_depth	mean_depth	min_leaves	max_leaves	mean_leaves
0		118.0	118.0	30206.0	4.0	4.0	4.0	12.0	16.0	15.754237


ModelMetricsBinomial: gbm
** Reported on train data. **

MSE: 0.0903010342522274
RMSE: 0.3005013049093587
LogLoss: 0.3058852024648929
Mean Per-Class Error: 0.053586726835477605
AUC: 0.9849289823899855
AUCPR: 0.9845032218245752
Gini: 0.969857964779971

Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.8963305169842031:
Confirmed	Rejected	Error	Rate
0	Confirmed	85162.0	5929.0	0.0651	(5929.0/91091.0)
1	Rejected	3834.0	87268.0	0.0421	(3834.0/91102.0)
2	Total	88996.0	93197.0	0.0536	(9763.0/182193.0)

Maximum Metrics: Maximum metrics at their respective thresholds
metric	threshold	value	idx
0	max f1	0.896331	0.947026	71.0
1	max f2	0.768116	0.960562	114.0
2	max f0point5	0.953977	0.949996	46.0
3	max accuracy	0.896331	0.946414	71.0
4	max precision	0.999375	1.000000	0.0
5	max recall	0.026622	1.000000	394.0
6	max specificity	0.999375	1.000000	0.0
7	max absolute_mcc	0.896331	0.893064	71.0
8	max min_per_class_accuracy	0.926899	0.944557	59.0
9	max mean_per_class_accuracy	0.896331	0.946413	71.0
10	max tns	0.999375	91091.000000	0.0
11	max fns	0.999375	85183.000000	0.0
12	max fps	0.014706	91091.000000	399.0
13	max tps	0.026622	91102.000000	394.0
14	max tnr	0.999375	1.000000	0.0
15	max fnr	0.999375	0.935029	0.0
16	max fpr	0.014706	1.000000	399.0
17	max tpr	0.026622	1.000000	394.0

Gains/Lift Table: Avg response rate: 50.00 %, avg score: 63.68 %
group	cumulative_data_fraction	lower_threshold	lift	cumulative_lift	response_rate	score	cumulative_response_rate	cumulative_score	capture_rate	cumulative_capture_rate	gain	cumulative_gain	kolmogorov_smirnov
0	1	0.010055	0.999426	1.999879	1.999879	1.000000	0.999494	1.000000	0.999494	0.020109	0.020109	99.987926	99.987926	0.020109
1	2	0.020006	0.999351	1.999879	1.999879	1.000000	0.999390	1.000000	0.999442	0.019901	0.040010	99.987926	99.987926	0.040010
2	3	0.030001	0.999256	1.999879	1.999879	1.000000	0.999303	1.000000	0.999396	0.019989	0.059999	99.987926	99.987926	0.059999
3	4	0.040013	0.999129	1.999879	1.999879	1.000000	0.999189	1.000000	0.999344	0.020022	0.080020	99.987926	99.987926	0.080020
4	5	0.050018	0.999018	1.999879	1.999879	1.000000	0.999073	1.000000	0.999290	0.020011	0.100031	99.987926	99.987926	0.100031
5	6	0.102348	0.998562	1.999879	1.999879	1.000000	0.998770	1.000000	0.999024	0.104652	0.204683	99.987926	99.987926	0.204683
6	7	0.150000	0.997705	1.999879	1.999879	1.000000	0.998223	1.000000	0.998770	0.095300	0.299982	99.987926	99.987926	0.299982
7	8	0.200030	0.996130	1.990006	1.997410	0.995063	0.996897	0.998765	0.998301	0.099559	0.399541	99.000602	99.740986	0.399047
8	9	0.300006	0.992806	1.951900	1.982244	0.976009	0.994586	0.991182	0.997063	0.195144	0.594685	95.189972	98.224370	0.589394
9	10	0.399999	0.985018	1.889446	1.959046	0.944780	0.989728	0.979582	0.995230	0.188931	0.783616	88.944570	95.904579	0.767281
10	11	0.500003	0.924788	1.612855	1.889805	0.806476	0.966758	0.944960	0.989535	0.161292	0.944908	61.285542	88.980544	0.889864
11	12	0.600029	0.549843	0.452563	1.650215	0.226295	0.756910	0.825157	0.950756	0.045268	0.990176	-54.743733	65.021458	0.780342
12	13	0.700175	0.264226	0.070039	1.424201	0.035021	0.377713	0.712143	0.868793	0.007014	0.997190	-92.996148	42.420086	0.594066
13	14	0.800728	0.106049	0.021614	1.248069	0.010808	0.168010	0.624072	0.780791	0.002173	0.999363	-97.838558	24.806876	0.397295
14	15	0.901039	0.058346	0.005471	1.109732	0.002736	0.078673	0.554900	0.702626	0.000549	0.999912	-99.452867	10.973241	0.197758
15	16	1.000000	0.012825	0.000887	1.000000	0.000444	0.037448	0.500030	0.636799	0.000088	1.000000	-99.911264	0.000000	0.000000


ModelMetricsBinomial: gbm
** Reported on cross-validation data. **

MSE: 0.04275160276103436
RMSE: 0.20676460712857594
LogLoss: 0.15094708992190958
Mean Per-Class Error: 0.17404820952328592
AUC: 0.9503884598986214
AUCPR: 0.9932875592467403
Gini: 0.9007769197972428

Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.6695771815716332:
Confirmed	Rejected	Error	Rate
0	Confirmed	6715.0	3279.0	0.3281	(3279.0/9994.0)
1	Rejected	1822.0	89280.0	0.02	(1822.0/91102.0)
2	Total	8537.0	92559.0	0.0505	(5101.0/101096.0)

Maximum Metrics: Maximum metrics at their respective thresholds
metric	threshold	value	idx
0	max f1	0.669577	0.972226	207.0
1	max f2	0.396207	0.983567	287.0
2	max f0point5	0.869813	0.969804	128.0
3	max accuracy	0.669577	0.949543	207.0
4	max precision	0.998930	1.000000	0.0
5	max recall	0.012285	1.000000	399.0
6	max specificity	0.998930	1.000000	0.0
7	max absolute_mcc	0.680802	0.701326	203.0
8	max min_per_class_accuracy	0.941177	0.886032	85.0
9	max mean_per_class_accuracy	0.938527	0.887177	87.0
10	max tns	0.998930	9994.000000	0.0
11	max fns	0.998930	89536.000000	0.0
12	max fps	0.012285	9994.000000	399.0
13	max tps	0.012285	91102.000000	399.0
14	max tnr	0.998930	1.000000	0.0
15	max fnr	0.998930	0.982810	0.0
16	max fpr	0.012285	1.000000	399.0
17	max tpr	0.012285	1.000000	399.0

Gains/Lift Table: Avg response rate: 90.11 %, avg score: 92.10 %
group	cumulative_data_fraction	lower_threshold	lift	cumulative_lift	response_rate	score	cumulative_response_rate	cumulative_score	capture_rate	cumulative_capture_rate	gain	cumulative_gain	kolmogorov_smirnov
0	1	0.010000	0.998859	1.109701	1.109701	1.000000	0.999044	1.000000	0.999044	0.011097	0.011097	10.970121	10.970121	0.011097
1	2	0.020030	0.998551	1.109701	1.109701	1.000000	0.998701	1.000000	0.998872	0.011130	0.022228	10.970121	10.970121	0.022228
2	3	0.030001	0.998353	1.108600	1.109335	0.999008	0.998450	0.999670	0.998732	0.011054	0.033281	10.860032	10.933534	0.033181
3	4	0.040002	0.998126	1.109701	1.109427	1.000000	0.998237	0.999753	0.998608	0.011097	0.044379	10.970121	10.942681	0.044279
4	5	0.050002	0.997911	1.107506	1.109043	0.998022	0.998016	0.999407	0.998490	0.011075	0.055454	10.750596	10.904264	0.055154
5	6	0.100004	0.997127	1.107945	1.108494	0.998417	0.997515	0.998912	0.998003	0.055399	0.110854	10.794501	10.849382	0.109753
6	7	0.150006	0.996621	1.109482	1.108823	0.999802	0.996892	0.999209	0.997633	0.055476	0.166330	10.948169	10.882311	0.165129
7	8	0.200018	0.996030	1.107726	1.108549	0.998220	0.996339	0.998961	0.997309	0.055399	0.221729	10.772588	10.854876	0.219628
8	9	0.300002	0.994515	1.104761	1.107286	0.995548	0.995287	0.997824	0.996635	0.110459	0.332188	10.476091	10.728635	0.325584
9	10	0.400006	0.992794	1.103664	1.106381	0.994560	0.993700	0.997008	0.995901	0.110371	0.442559	10.366426	10.638081	0.430452
10	11	0.500000	0.990168	1.097626	1.104630	0.989119	0.991532	0.995430	0.995028	0.109756	0.552315	9.762612	10.462998	0.529201
11	12	0.600024	0.985578	1.096862	1.103335	0.988430	0.988119	0.994263	0.993876	0.109712	0.662027	9.686151	10.333498	0.627206
12	13	0.700008	0.976392	1.083243	1.100465	0.976157	0.981831	0.991677	0.992155	0.108307	0.770334	8.324316	10.046520	0.711399
13	14	0.800071	0.947801	1.059240	1.095309	0.954527	0.965276	0.987031	0.988794	0.105991	0.876325	5.924030	9.530929	0.771362
14	15	0.899996	0.748109	0.919661	1.075807	0.828747	0.876867	0.969457	0.976367	0.091897	0.968222	-8.033869	7.580743	0.690156
15	16	1.000000	0.008120	0.317763	1.000000	0.286350	0.422683	0.901143	0.920996	0.031778	1.000000	-68.223689	0.000000	0.000000


Cross-Validation Metrics Summary:
mean	sd	cv_1_valid	cv_2_valid	cv_3_valid	cv_4_valid	cv_5_valid	cv_6_valid	cv_7_valid	cv_8_valid	cv_9_valid	cv_10_valid
0	accuracy	0.958255	0.032623	0.992189	0.906282	0.985917	0.979368	0.961009	0.980836	0.938917	0.902098	0.979815	0.956122
1	auc	0.946056	0.054639	0.990801	0.818816	0.981806	0.979030	0.879134	0.981817	0.953302	0.954326	0.961103	0.960422
2	err	0.041745	0.032623	0.007811	0.093718	0.014083	0.020632	0.038991	0.019164	0.061083	0.097902	0.020185	0.043878
3	err_count	421.900000	380.934080	126.000000	1277.000000	126.000000	184.000000	351.000000	170.000000	547.000000	868.000000	179.000000	391.000000
4	f0point5	0.969089	0.026691	0.994322	0.925449	0.990838	0.988742	0.968881	0.986800	0.964772	0.919883	0.984902	0.966301
5	f1	0.975589	0.021210	0.996071	0.950601	0.992753	0.987624	0.979325	0.989897	0.965250	0.930337	0.989411	0.974619
6	f2	0.982298	0.017406	0.997826	0.977160	0.994675	0.986510	0.989996	0.993013	0.965728	0.941031	0.993962	0.983081
7	lift_top_group	1.127187	0.128008	1.009007	1.097269	1.032545	1.184764	1.079894	1.059983	1.138734	1.450589	1.045346	1.173736
8	logloss	0.156332	0.116192	0.023445	0.264161	0.052835	0.136115	0.155948	0.068952	0.166774	0.406861	0.072387	0.215843
9	max_per_class_error	0.385081	0.275859	0.763889	0.951789	0.322695	0.053061	0.492492	0.256972	0.256645	0.200436	0.320833	0.231994
10	mcc	0.677837	0.233629	0.397828	0.140350	0.749649	0.925690	0.673372	0.808560	0.713078	0.767448	0.784728	0.817669
11	mean_per_class_accuracy	0.800907	0.134452	0.617555	0.521958	0.836633	0.966353	0.752374	0.869064	0.854701	0.873931	0.838093	0.878405
12	mean_per_class_error	0.199093	0.134452	0.382445	0.478042	0.163367	0.033647	0.247626	0.130936	0.145299	0.126069	0.161907	0.121595
13	mse	0.044397	0.036128	0.005978	0.077864	0.013994	0.039601	0.037525	0.016266	0.049340	0.123698	0.017373	0.062328
14	pr_auc	0.990461	0.009419	0.999911	0.972189	0.999347	0.993748	0.984729	0.998765	0.992243	0.978471	0.996314	0.988894
15	precision	0.964866	0.030711	0.993160	0.909407	0.989565	0.989488	0.962041	0.984746	0.964453	0.913044	0.981919	0.960835
16	r2	0.494239	0.188587	0.324299	0.089002	0.541570	0.712338	0.452266	0.695310	0.538826	0.422340	0.660674	0.505762
17	recall	0.986895	0.016708	0.998999	0.995705	0.995961	0.985768	0.997241	0.995101	0.966048	0.948298	0.997019	0.988804
18	rmse	0.195020	0.084089	0.077316	0.279041	0.118295	0.199000	0.193714	0.127540	0.222127	0.351708	0.131805	0.249656
19	specificity	0.614919	0.275859	0.236111	0.048212	0.677305	0.946939	0.507508	0.743028	0.743355	0.799564	0.679167	0.768006

Scoring History:
timestamp	duration	number_of_trees	training_rmse	training_logloss	training_auc	training_pr_auc	training_lift	training_classification_error
0		2022-01-01 14:04:54	31 min 18.205 sec	0.0	0.641008	1.209022	0.500000	0.500030	1.000000	0.499970
1		2022-01-01 14:05:02	31 min 26.100 sec	5.0	0.595860	0.976821	0.945127	0.925178	1.972552	0.108275
2		2022-01-01 14:05:06	31 min 29.673 sec	10.0	0.547076	0.815921	0.960690	0.953866	1.981215	0.096661
3		2022-01-01 14:05:09	31 min 33.268 sec	15.0	0.499857	0.700545	0.965672	0.962498	1.999879	0.088225
4		2022-01-01 14:05:13	31 min 36.915 sec	20.0	0.461115	0.617657	0.968790	0.966381	1.999879	0.084394
5		2022-01-01 14:05:17	31 min 40.531 sec	25.0	0.428532	0.554491	0.970688	0.968351	1.999879	0.081414
6		2022-01-01 14:05:20	31 min 44.132 sec	30.0	0.404123	0.507631	0.973119	0.971244	1.999879	0.076326
7		2022-01-01 14:05:24	31 min 47.738 sec	35.0	0.383425	0.468966	0.974569	0.972816	1.999879	0.074103
8		2022-01-01 14:05:27	31 min 51.348 sec	40.0	0.369493	0.442191	0.976025	0.974657	1.999879	0.070546
9		2022-01-01 14:05:31	31 min 54.938 sec	45.0	0.356968	0.418272	0.977397	0.976381	1.999879	0.068093
10		2022-01-01 14:05:35	31 min 58.532 sec	50.0	0.347923	0.401312	0.978152	0.977111	1.999879	0.065661
11		2022-01-01 14:05:38	32 min 2.135 sec	55.0	0.339642	0.384789	0.979088	0.978137	1.999879	0.064273
12		2022-01-01 14:05:42	32 min 5.704 sec	60.0	0.333728	0.373547	0.979657	0.978653	1.999879	0.063350
13		2022-01-01 14:05:45	32 min 9.295 sec	65.0	0.327885	0.362005	0.980386	0.979474	1.999879	0.062439
14		2022-01-01 14:05:49	32 min 12.980 sec	70.0	0.323225	0.352893	0.980885	0.979973	1.999879	0.060930
15		2022-01-01 14:05:53	32 min 16.565 sec	75.0	0.319905	0.346192	0.981426	0.980589	1.999879	0.059410
16		2022-01-01 14:05:56	32 min 20.216 sec	80.0	0.316078	0.338094	0.982122	0.981388	1.999879	0.058405
17		2022-01-01 14:06:00	32 min 23.814 sec	85.0	0.313502	0.333247	0.982498	0.981777	1.999879	0.057516
18		2022-01-01 14:06:03	32 min 27.388 sec	90.0	0.310906	0.327768	0.982948	0.982295	1.999879	0.056753
19		2022-01-01 14:06:07	32 min 31.024 sec	95.0	0.308454	0.322831	0.983331	0.982683	1.999879	0.056385

See the whole table with table.as_data_frame()

Variable Importances:
variable	relative_importance	scaled_importance	percentage
0	C4	30737.367188	1.000000	0.168023
1	C22	22991.685547	0.748004	0.125682
2	C64	16325.849609	0.531140	0.089244
3	C14	15652.251953	0.509226	0.085562
4	C15	11210.112305	0.364706	0.061279
5	C23	10872.648438	0.353727	0.059434
6	C63	10376.408203	0.337583	0.056722
7	C30	8198.322266	0.266722	0.044815
8	C19	5859.145020	0.190620	0.032028
9	C1	4212.735840	0.137056	0.023029
10	C112	3991.229492	0.129849	0.021818
11	C13	3902.584473	0.126965	0.021333
12	C67	3230.167969	0.105089	0.017657
13	C70	3103.609619	0.100972	0.016966
14	C116	2902.303223	0.094423	0.015865
15	C127	2594.122314	0.084396	0.014181
16	C80	2020.162720	0.065723	0.011043
17	C71	1886.449219	0.061373	0.010312
18	C164	1597.722656	0.051980	0.008734
19	C111	1577.282715	0.051315	0.008622

See the whole table with table.as_data_frame()** Reported on cross-validation data. **


LEADERBOARD:
model_id	auc	logloss	aucpr	mean_per_class_error	rmse	mse
GBM_grid_1_AutoML_1_20220101_85351_model_2	0.950388	0.150947	0.993288	0.174048	0.206765	0.0427516
StackedEnsemble_BestOfFamily_8_AutoML_1_20220101_85351	0.946295	0.15239	0.992776	0.162871	0.204979	0.0420162
StackedEnsemble_AllModels_7_AutoML_1_20220101_85351	0.945677	0.152965	0.992656	0.195551	0.205663	0.0422971
GBM_2_AutoML_1_20220101_85351	0.945524	0.163915	0.992782	0.223884	0.216974	0.0470779
StackedEnsemble_BestOfFamily_7_AutoML_1_20220101_85351	0.945342	0.159615	0.991653	0.183444	0.213151	0.0454332
StackedEnsemble_BestOfFamily_6_AutoML_1_20220101_85351	0.945296	0.160846	0.992258	0.193073	0.212749	0.045262
XGBoost_3_AutoML_1_20220101_85351	0.944403	0.241057	0.992681	0.217866	0.261455	0.0683586
GBM_1_AutoML_1_20220101_85351	0.944222	0.163894	0.992487	0.205905	0.21296	0.0453519
XGBoost_grid_1_AutoML_1_20220101_85351_model_1	0.944147	0.157721	0.992293	0.220044	0.210978	0.0445117
GBM_3_AutoML_1_20220101_85351	0.943117	0.170922	0.992287	0.216755	0.221519	0.0490709
XGBoost_grid_1_AutoML_1_20220101_85351_model_3	0.942035	0.168399	0.992146	0.210489	0.217338	0.0472356
GBM_4_AutoML_1_20220101_85351	0.941499	0.18234	0.992178	0.225946	0.227573	0.0517896
StackedEnsemble_BestOfFamily_5_AutoML_1_20220101_85351	0.941324	0.176487	0.991989	0.198545	0.219668	0.0482538
DeepLearning_grid_3_AutoML_1_20220101_85351_model_1	0.941207	0.345681	0.991743	0.185765	0.234702	0.0550849
StackedEnsemble_AllModels_4_AutoML_1_20220101_85351	0.94016	0.182528	0.991939	0.221412	0.224166	0.0502502
StackedEnsemble_BestOfFamily_4_AutoML_1_20220101_85351	0.939855	0.176585	0.991795	0.206708	0.221602	0.0491075
StackedEnsemble_BestOfFamily_3_AutoML_1_20220101_85351	0.939026	0.182836	0.991873	0.200242	0.225218	0.0507231
GBM_5_AutoML_1_20220101_85351	0.938769	0.173107	0.991387	0.230718	0.223812	0.0500919
GBM_grid_1_AutoML_1_20220101_85351_model_1	0.938484	0.197201	0.991158	0.22723	0.233864	0.0546923
StackedEnsemble_AllModels_3_AutoML_1_20220101_85351	0.938121	0.182794	0.991689	0.241287	0.228349	0.0521433
StackedEnsemble_AllModels_2_AutoML_1_20220101_85351	0.938066	0.182269	0.9918	0.206702	0.226235	0.0511823
StackedEnsemble_BestOfFamily_2_AutoML_1_20220101_85351	0.937778	0.172196	0.991528	0.226754	0.2239	0.0501311
XGBoost_grid_1_AutoML_1_20220101_85351_model_2	0.937617	0.174649	0.991419	0.22907	0.21879	0.0478693
XGBoost_2_AutoML_1_20220101_85351	0.937374	0.229744	0.99136	0.259327	0.260801	0.0680171
StackedEnsemble_AllModels_6_AutoML_1_20220101_85351	0.937208	0.173124	0.989945	0.208277	0.222452	0.0494848
StackedEnsemble_AllModels_1_AutoML_1_20220101_85351	0.936354	0.174083	0.991427	0.209359	0.225131	0.0506838
StackedEnsemble_BestOfFamily_1_AutoML_1_20220101_85351	0.936016	0.170754	0.991291	0.231023	0.222075	0.0493174
XGBoost_1_AutoML_1_20220101_85351	0.935593	0.249395	0.991256	0.260315	0.271379	0.0736463
StackedEnsemble_AllModels_5_AutoML_1_20220101_85351	0.934086	0.191298	0.990761	0.247068	0.232949	0.0542651
XRT_1_AutoML_1_20220101_85351	0.928564	0.243067	0.988946	0.212989	0.270925	0.0734004
DRF_1_AutoML_1_20220101_85351	0.926024	0.24835	0.988272	0.197772	0.273738	0.0749324
DeepLearning_grid_2_AutoML_1_20220101_85351_model_1	0.921659	0.485624	0.988428	0.243217	0.26162	0.068445
DeepLearning_1_AutoML_1_20220101_85351	0.919168	0.301028	0.988282	0.211228	0.240297	0.0577429
DeepLearning_grid_1_AutoML_1_20220101_85351_model_1	0.914562	0.685623	0.988564	0.284287	0.281525	0.0792561
GLM_1_AutoML_1_20220101_85351	0.887302	0.199002	0.983809	0.274651	0.232632	0.0541177
