AutoML progress: |
16:46:07.988: Fold column FOLD will be used for cross-validation. nfolds parameter will be ignored.
16:46:08.155: _train param, Dropping bad and constant columns: [C99, C98, C19, C107, C106, C139, C138, C103, C102, C124, C123, C122, C151, C150, C91, C90, C95, C94]

█████████████████████████████████████████████████████████
17:02:49.470: _train param, Dropping bad and constant columns: [C99, C98, C19, C107, C106, C139, C138, C103, C102, C124, C123, C122, C151, C150, C91, C90, C95, C94]

█████
17:22:53.740: _train param, Dropping bad and constant columns: [C99, C98, C19, C107, C106, C139, C138, C103, C102, C124, C123, C122, C151, C150, C91, C90, C95, C94]


17:39:38.988: _train param, Dropping unused columns: [C99, C98, C19, C107, C106, C139, C138, C103, C102, C124, C123, C122, C151, C150, C91, C90, C95, C94]


17:39:51.11: _train param, Dropping bad and constant columns: [C99, C98, C19, C107, C106, C139, C138, C103, C102, C124, C123, C122, C151, C150, C91, C90, C95, C94]

█
17:55:36.278: _train param, Dropping bad and constant columns: [C99, C98, C19, C107, C106, C139, C138, C103, C102, C124, C123, C122, C151, C150, C91, C90, C95, C94]


18:03:00.387: _train param, Dropping bad and constant columns: [C99, C98, C19, C107, C106, C139, C138, C103, C102, C124, C123, C122, C151, C150, C91, C90, C95, C94]


18:15:12.512: _train param, Dropping bad and constant columns: [C99, C98, C19, C107, C106, C139, C138, C103, C102, C124, C123, C122, C151, C150, C91, C90, C95, C94]


18:27:41.682: _train param, Dropping bad and constant columns: [C99, C98, C19, C107, C106, C139, C138, C103, C102, C124, C123, C122, C151, C150, C91, C90, C95, C94]


18:38:20.826: _train param, Dropping unused columns: [C99, C98, C19, C107, C106, C139, C138, C103, C102, C124, C123, C122, C151, C150, C91, C90, C95, C94]


18:38:31.859: _train param, Dropping unused columns: [C99, C98, C19, C107, C106, C139, C138, C103, C102, C124, C123, C122, C151, C150, C91, C90, C95, C94]


18:38:44.874: _train param, Dropping bad and constant columns: [C99, C98, C19, C107, C106, C139, C138, C103, C102, C124, C123, C122, C151, C150, C91, C90, C95, C94]


18:49:02.6: _train param, Dropping bad and constant columns: [C99, C98, C19, C107, C106, C139, C138, C103, C102, C124, C123, C122, C151, C150, C91, C90, C95, C94]


18:57:18.147: _train param, Dropping bad and constant columns: [C99, C98, C19, C107, C106, C139, C138, C103, C102, C124, C123, C122, C151, C150, C91, C90, C95, C94]


19:05:21.269: _train param, Dropping bad and constant columns: [C99, C98, C19, C107, C106, C139, C138, C103, C102, C124, C123, C122, C151, C150, C91, C90, C95, C94]


19:10:41.360: _train param, Dropping unused columns: [C99, C98, C19, C107, C106, C139, C138, C103, C102, C124, C123, C122, C151, C150, C91, C90, C95, C94]


19:10:54.385: _train param, Dropping unused columns: [C99, C98, C19, C107, C106, C139, C138, C103, C102, C124, C123, C122, C151, C150, C91, C90, C95, C94]


20:20:58.431: _train param, Dropping unused columns: [C99, C98, C19, C107, C106, C139, C138, C103, C102, C124, C123, C122, C151, C150, C91, C90, C95, C94]


20:21:10.451: _train param, Dropping unused columns: [C99, C98, C19, C107, C106, C139, C138, C103, C102, C124, C123, C122, C151, C150, C91, C90, C95, C94]


20:55:34.901: _train param, Dropping unused columns: [C99, C98, C19, C107, C106, C139, C138, C103, C102, C124, C123, C122, C151, C150, C91, C90, C95, C94]


20:55:56.939: _train param, Dropping unused columns: [C99, C98, C19, C107, C106, C139, C138, C103, C102, C124, C123, C122, C151, C150, C91, C90, C95, C94]


20:57:14.976: _train param, Dropping unused columns: [C99, C98, C19, C107, C106, C139, C138, C103, C102, C124, C123, C122, C151, C150, C91, C90, C95, C94]


20:58:14.8: _train param, Dropping unused columns: [C99, C98, C19, C107, C106, C139, C138, C103, C102, C124, C123, C122, C151, C150, C91, C90, C95, C94]


21:00:54.55: _train param, Dropping unused columns: [C99, C98, C19, C107, C106, C139, C138, C103, C102, C124, C123, C122, C151, C150, C91, C90, C95, C94]


21:02:46.103: _train param, Dropping unused columns: [C99, C98, C19, C107, C106, C139, C138, C103, C102, C124, C123, C122, C151, C150, C91, C90, C95, C94]


21:04:35.143: _train param, Dropping unused columns: [C99, C98, C19, C107, C106, C139, C138, C103, C102, C124, C123, C122, C151, C150, C91, C90, C95, C94]

| (done) 100%
Model Details
=============
H2OXGBoostEstimator :  XGBoost
Model Key:  XGBoost_grid_1_AutoML_1_20220102_164607_model_2


Model Summary:
number_of_trees
0		61.0


ModelMetricsBinomial: xgboost
** Reported on train data. **

MSE: 0.0017201090055052439
RMSE: 0.04147419686389652
LogLoss: 0.008376959879360203
Mean Per-Class Error: 0.005606345339671187
AUC: 0.9999028017500278
AUCPR: 0.9999891327957339
Gini: 0.9998056035000555

Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5861624032258987:
Confirmed	Rejected	Error	Rate
0	Confirmed	9906.0	103.0	0.0103	(103.0/10009.0)
1	Rejected	84.0	91027.0	0.0009	(84.0/91111.0)
2	Total	9990.0	91130.0	0.0018	(187.0/101120.0)

Maximum Metrics: Maximum metrics at their respective thresholds
metric	threshold	value	idx
0	max f1	0.586162	0.998974	194.0
1	max f2	0.414288	0.999309	227.0
2	max f0point5	0.735080	0.999128	163.0
3	max accuracy	0.586162	0.998151	194.0
4	max precision	0.999936	1.000000	0.0
5	max recall	0.035244	1.000000	352.0
6	max specificity	0.999936	1.000000	0.0
7	max absolute_mcc	0.586162	0.989624	194.0
8	max min_per_class_accuracy	0.842026	0.996093	135.0
9	max mean_per_class_accuracy	0.778773	0.996234	153.0
10	max tns	0.999936	10009.000000	0.0
11	max fns	0.999936	73186.000000	0.0
12	max fps	0.000399	10009.000000	399.0
13	max tps	0.035244	91111.000000	352.0
14	max tnr	0.999936	1.000000	0.0
15	max fnr	0.999936	0.803262	0.0
16	max fpr	0.000399	1.000000	399.0
17	max tpr	0.035244	1.000000	352.0

Gains/Lift Table: Avg response rate: 90.10 %, avg score: 90.11 %
group	cumulative_data_fraction	lower_threshold	lift	cumulative_lift	response_rate	score	cumulative_response_rate	cumulative_score	capture_rate	cumulative_capture_rate	gain	cumulative_gain	kolmogorov_smirnov
0	1	0.010067	0.999967	1.109855	1.109855	1.000000	0.999973	1.000000	0.999973	0.011173	0.011173	10.985501	10.985501	0.011173
1	2	0.020085	0.999960	1.109855	1.109855	1.000000	0.999963	1.000000	0.999968	0.011118	0.022291	10.985501	10.985501	0.022291
2	3	0.030004	0.999954	1.109855	1.109855	1.000000	0.999957	1.000000	0.999965	0.011009	0.033300	10.985501	10.985501	0.033300
3	4	0.040437	0.999951	1.109855	1.109855	1.000000	0.999952	1.000000	0.999961	0.011579	0.044879	10.985501	10.985501	0.044879
4	5	0.051661	0.999948	1.109855	1.109855	1.000000	0.999949	1.000000	0.999959	0.012457	0.057337	10.985501	10.985501	0.057337
5	6	0.100356	0.999932	1.109855	1.109855	1.000000	0.999939	1.000000	0.999949	0.054044	0.111381	10.985501	10.985501	0.111381
6	7	0.150237	0.999916	1.109855	1.109855	1.000000	0.999924	1.000000	0.999941	0.055361	0.166742	10.985501	10.985501	0.166742
7	8	0.200079	0.999894	1.109855	1.109855	1.000000	0.999906	1.000000	0.999932	0.055317	0.222059	10.985501	10.985501	0.222059
8	9	0.300099	0.999833	1.109855	1.109855	1.000000	0.999866	1.000000	0.999910	0.111007	0.333066	10.985501	10.985501	0.333066
9	10	0.400020	0.999740	1.109855	1.109855	1.000000	0.999789	1.000000	0.999880	0.110898	0.443964	10.985501	10.985501	0.443964
10	11	0.500010	0.999603	1.109855	1.109855	1.000000	0.999678	1.000000	0.999839	0.110975	0.554938	10.985501	10.985501	0.554938
11	12	0.600010	0.999360	1.109855	1.109855	1.000000	0.999495	1.000000	0.999782	0.110986	0.665924	10.985501	10.985501	0.665924
12	13	0.700000	0.998798	1.109855	1.109855	1.000000	0.999123	1.000000	0.999688	0.110975	0.776899	10.985501	10.985501	0.776899
13	14	0.800000	0.996945	1.109745	1.109841	0.999901	0.998093	0.999988	0.999488	0.110975	0.887873	10.974526	10.984129	0.887773
14	15	0.900000	0.727795	1.103489	1.109135	0.994264	0.979378	0.999352	0.997254	0.110349	0.998222	10.348915	10.913550	0.992327
15	16	1.000000	0.000165	0.017781	1.000000	0.016021	0.035704	0.901019	0.901099	0.001778	1.000000	-98.221949	0.000000	0.000000


ModelMetricsBinomial: xgboost
** Reported on cross-validation data. **

MSE: 0.028713995057916504
RMSE: 0.16945204353420026
LogLoss: 0.109975012201212
Mean Per-Class Error: 0.13268456584681343
AUC: 0.9692020735902998
AUCPR: 0.9956368170220707
Gini: 0.9384041471805995

Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.42443053069568815:
Confirmed	Rejected	Error	Rate
0	Confirmed	7482.0	2527.0	0.2525	(2527.0/10009.0)
1	Rejected	1175.0	89936.0	0.0129	(1175.0/91111.0)
2	Total	8657.0	92463.0	0.0366	(3702.0/101120.0)

Maximum Metrics: Maximum metrics at their respective thresholds
metric	threshold	value	idx
0	max f1	0.424431	0.979834	252.0
1	max f2	0.169093	0.988090	322.0
2	max f0point5	0.823103	0.981186	140.0
3	max accuracy	0.424431	0.963390	252.0
4	max precision	0.999832	0.999819	0.0
5	max recall	0.002881	1.000000	398.0
6	max specificity	0.999832	0.999800	0.0
7	max absolute_mcc	0.761369	0.785921	163.0
8	max min_per_class_accuracy	0.957107	0.919073	70.0
9	max mean_per_class_accuracy	0.924192	0.921790	94.0
10	max tns	0.999832	10007.000000	0.0
11	max fns	0.999832	80093.000000	0.0
12	max fps	0.001562	10009.000000	399.0
13	max tps	0.002881	91111.000000	398.0
14	max tnr	0.999832	0.999800	0.0
15	max fnr	0.999832	0.879071	0.0
16	max fpr	0.001562	1.000000	399.0
17	max tpr	0.002881	1.000000	398.0

Gains/Lift Table: Avg response rate: 90.10 %, avg score: 90.50 %
group	cumulative_data_fraction	lower_threshold	lift	cumulative_lift	response_rate	score	cumulative_response_rate	cumulative_score	capture_rate	cumulative_capture_rate	gain	cumulative_gain	kolmogorov_smirnov
0	1	0.010028	0.999948	1.109855	1.109855	1.000000	0.999965	1.000000	0.999965	0.011129	0.011129	10.985501	10.985501	0.011129
1	2	0.020006	0.999922	1.109855	1.109855	1.000000	0.999935	1.000000	0.999950	0.011074	0.022204	10.985501	10.985501	0.022204
2	3	0.030004	0.999898	1.109855	1.109855	1.000000	0.999910	1.000000	0.999936	0.011096	0.033300	10.985501	10.985501	0.033300
3	4	0.040051	0.999875	1.109855	1.109855	1.000000	0.999886	1.000000	0.999924	0.011151	0.044451	10.985501	10.985501	0.044451
4	5	0.050020	0.999850	1.109855	1.109855	1.000000	0.999863	1.000000	0.999912	0.011063	0.055515	10.985501	10.985501	0.055515
5	6	0.100059	0.999723	1.109416	1.109636	0.999605	0.999787	0.999802	0.999850	0.055515	0.111029	10.941633	10.963563	0.110830
6	7	0.150000	0.999603	1.108976	1.109416	0.999208	0.999663	0.999604	0.999787	0.055383	0.166412	10.897592	10.941599	0.165813
7	8	0.200010	0.999483	1.105905	1.108538	0.996441	0.999543	0.998813	0.999726	0.055306	0.221719	10.590457	10.853800	0.219321
8	9	0.300000	0.999168	1.106233	1.107770	0.996736	0.999335	0.998121	0.999596	0.110612	0.332331	10.623270	10.776964	0.326636
9	10	0.400010	0.998649	1.102612	1.106480	0.993474	0.998933	0.996959	0.999430	0.110272	0.442603	10.261182	10.648009	0.430314
10	11	0.500079	0.997737	1.103823	1.105948	0.994565	0.998232	0.996480	0.999190	0.110459	0.553062	10.382260	10.594831	0.535278
11	12	0.600099	0.996071	1.100637	1.105063	0.991695	0.996982	0.995682	0.998822	0.110086	0.663147	10.063731	10.506311	0.636971
12	13	0.700000	0.992905	1.098759	1.104163	0.990002	0.994685	0.994872	0.998232	0.109767	0.772914	9.875866	10.416337	0.736647
13	14	0.800020	0.976874	1.079788	1.101116	0.972909	0.987251	0.992126	0.996859	0.108000	0.880914	7.978775	10.111589	0.817272
14	15	0.900059	0.691468	0.968435	1.086369	0.872578	0.911214	0.978838	0.987340	0.096882	0.977796	-3.156483	8.636873	0.785369
15	16	1.000000	0.000290	0.222169	1.000000	0.200178	0.162956	0.901019	0.904950	0.022204	1.000000	-77.783132	0.000000	0.000000


Cross-Validation Metrics Summary:
mean	sd	cv_1_valid	cv_2_valid	cv_3_valid	cv_4_valid	cv_5_valid	cv_6_valid	cv_7_valid	cv_8_valid	cv_9_valid	cv_10_valid
0	accuracy	0.976588	0.017468	0.994545	0.982900	0.987482	0.989011	0.964786	0.979822	0.979564	0.933183	0.983085	0.971496
1	auc	0.972727	0.033346	0.990225	0.990120	0.974979	0.994245	0.880080	0.974961	0.988053	0.976902	0.976127	0.981576
2	err	0.023413	0.017468	0.005455	0.017100	0.012518	0.010989	0.035214	0.020178	0.020436	0.066817	0.016915	0.028504
3	err_count	220.800000	150.009480	88.000000	233.000000	112.000000	98.000000	317.000000	179.000000	183.000000	594.000000	150.000000	254.000000
4	f0point5	0.982721	0.017191	0.996876	0.989166	0.991440	0.993659	0.975238	0.984868	0.990110	0.937041	0.987121	0.981693
5	f1	0.986099	0.012617	0.997250	0.990582	0.993560	0.993418	0.981179	0.989388	0.988330	0.952842	0.991119	0.983318
6	f2	0.989547	0.008321	0.997624	0.992001	0.995690	0.993178	0.987193	0.993949	0.986556	0.969185	0.995149	0.984948
7	lift_top_group	1.130508	0.128220	1.009007	1.104214	1.032545	1.197368	1.079894	1.059983	1.138734	1.452377	1.057225	1.173736
8	logloss	0.113666	0.075359	0.032312	0.158651	0.048037	0.100632	0.171913	0.066659	0.077024	0.276807	0.056632	0.147990
9	max_per_class_error	0.212219	0.128686	0.375000	0.113530	0.308511	0.031293	0.366366	0.306773	0.062328	0.171181	0.275000	0.112206
10	mcc	0.827498	0.089915	0.670809	0.898170	0.776845	0.960156	0.717496	0.794650	0.906499	0.842477	0.822241	0.885639
11	mean_per_class_accuracy	0.889834	0.062684	0.811437	0.939710	0.844302	0.980863	0.812438	0.845120	0.961524	0.904607	0.861427	0.936916
12	mean_per_class_error	0.110166	0.062684	0.188563	0.060290	0.155698	0.019137	0.187562	0.154880	0.038476	0.095393	0.138573	0.063084
13	mse	0.029402	0.018735	0.009124	0.045802	0.011561	0.032962	0.031893	0.017349	0.019892	0.068026	0.014333	0.043081
14	pr_auc	0.995997	0.004773	0.999904	0.998806	0.998990	0.998659	0.985801	0.997945	0.998049	0.988816	0.997458	0.995539
15	precision	0.980508	0.020251	0.996627	0.988225	0.990031	0.993819	0.971318	0.981878	0.991301	0.926795	0.984474	0.980613
16	r2	0.589946	0.240991	-0.031330	0.464119	0.621284	0.760566	0.534476	0.675038	0.814072	0.682800	0.720049	0.658382
17	recall	0.991888	0.006115	0.997873	0.992950	0.997115	0.993018	0.991243	0.997013	0.985376	0.980395	0.997854	0.986038
18	rmse	0.163804	0.053441	0.095519	0.214015	0.107520	0.181553	0.178586	0.131714	0.141040	0.260818	0.119720	0.207560
19	specificity	0.787781	0.128686	0.625000	0.886470	0.691489	0.968708	0.633634	0.693227	0.937672	0.828819	0.725000	0.887794

Scoring History:
timestamp	duration	number_of_trees	training_rmse	training_logloss	training_auc	training_pr_auc	training_lift	training_classification_error
0		2022-01-02 19:38:32	27 min 23.164 sec	0.0	0.500000	0.693147	0.500000	0.901019	1.000000	0.098981
1		2022-01-02 19:38:42	27 min 33.248 sec	5.0	0.144623	0.138668	0.982278	0.996252	1.105845	0.012213
2		2022-01-02 19:38:50	27 min 41.464 sec	10.0	0.089833	0.052141	0.994391	0.999031	1.109263	0.008525
3		2022-01-02 19:38:58	27 min 48.971 sec	15.0	0.077023	0.030426	0.997833	0.999701	1.109855	0.006824
4		2022-01-02 19:39:05	27 min 56.344 sec	20.0	0.069044	0.022265	0.998824	0.999850	1.109855	0.005568
5		2022-01-02 19:39:13	28 min 3.848 sec	25.0	0.062882	0.017788	0.999240	0.999909	1.109855	0.004608
6		2022-01-02 19:39:20	28 min 11.428 sec	30.0	0.058289	0.015227	0.999490	0.999941	1.109855	0.003926
7		2022-01-02 19:39:28	28 min 18.893 sec	35.0	0.054432	0.013352	0.999633	0.999958	1.109855	0.003333
8		2022-01-02 19:39:36	28 min 26.785 sec	40.0	0.051343	0.011968	0.999719	0.999968	1.109855	0.002996
9		2022-01-02 19:39:43	28 min 34.393 sec	45.0	0.048530	0.010863	0.999792	0.999977	1.109855	0.002680
10		2022-01-02 19:39:51	28 min 41.843 sec	50.0	0.046061	0.009940	0.999838	0.999982	1.109855	0.002354
11		2022-01-02 19:39:58	28 min 49.414 sec	55.0	0.043823	0.009152	0.999872	0.999986	1.109855	0.002116
12		2022-01-02 19:40:05	28 min 56.342 sec	60.0	0.041856	0.008493	0.999895	0.999988	1.109855	0.001830
13		2022-01-02 19:40:08	28 min 58.634 sec	61.0	0.041474	0.008377	0.999903	0.999989	1.109855	0.001849

Variable Importances:
variable	relative_importance	scaled_importance	percentage
0	C1	36758.253906	1.000000	0.442300
1	C15.F	5322.284668	0.144792	0.064041
2	C16	2651.994385	0.072147	0.031911
3	C15.T	2387.519043	0.064952	0.028728
4	C166.F	2162.722168	0.058836	0.026023
5	C24	1903.121216	0.051774	0.022900
6	C5	1741.489746	0.047377	0.020955
7	C20	1741.222046	0.047370	0.020952
8	C23	1623.114746	0.044156	0.019530
9	C31	1180.790283	0.032123	0.014208
10	C128	1100.274292	0.029933	0.013239
11	C33	1070.152100	0.029113	0.012877
12	C27	980.576538	0.026676	0.011799
13	C2.T	937.275391	0.025498	0.011278
14	C117	855.089966	0.023263	0.010289
15	C71	811.653320	0.022081	0.009766
16	C75	808.771484	0.022002	0.009732
17	C81	776.783325	0.021132	0.009347
18	C14	771.471375	0.020988	0.009283
19	C127	771.172852	0.020980	0.009279

See the whole table with table.as_data_frame()


LEADERBOARD:
model_id	auc	logloss	aucpr	mean_per_class_error	rmse	mse
XGBoost_grid_1_AutoML_1_20220102_164607_model_2	0.969202	0.109975	0.995637	0.132685	0.169452	0.028714
XGBoost_2_AutoML_1_20220102_164607	0.968241	0.115353	0.995583	0.107629	0.169538	0.0287431
StackedEnsemble_BestOfFamily_7_AutoML_1_20220102_164607	0.967908	0.11963	0.995591	0.10378	0.17529	0.0307265
StackedEnsemble_BestOfFamily_4_AutoML_1_20220102_164607	0.967367	0.112413	0.995582	0.143913	0.173599	0.0301366
GBM_grid_1_AutoML_1_20220102_164607_model_1	0.967329	0.104734	0.995549	0.1158	0.163013	0.0265734
StackedEnsemble_BestOfFamily_5_AutoML_1_20220102_164607	0.966976	0.118618	0.995367	0.123071	0.177406	0.0314728
StackedEnsemble_BestOfFamily_3_AutoML_1_20220102_164607	0.966313	0.112941	0.995416	0.152432	0.173729	0.0301819
GBM_2_AutoML_1_20220102_164607	0.966211	0.108261	0.995382	0.129632	0.167831	0.0281673
StackedEnsemble_AllModels_5_AutoML_1_20220102_164607	0.965693	0.119854	0.995134	0.121169	0.176641	0.0312021
XGBoost_1_AutoML_1_20220102_164607	0.965011	0.114912	0.994966	0.108358	0.170919	0.0292134
XGBoost_3_AutoML_1_20220102_164607	0.964939	0.118888	0.995295	0.143467	0.177004	0.0313306
XGBoost_grid_1_AutoML_1_20220102_164607_model_3	0.96488	0.11693	0.995047	0.13126	0.173786	0.0302015
StackedEnsemble_AllModels_3_AutoML_1_20220102_164607	0.964677	0.111395	0.995086	0.164135	0.171222	0.029317
XGBoost_grid_1_AutoML_1_20220102_164607_model_1	0.96458	0.114847	0.99485	0.11815	0.173429	0.0300778
StackedEnsemble_AllModels_4_AutoML_1_20220102_164607	0.964479	0.114685	0.99509	0.151867	0.173616	0.0301425
GBM_3_AutoML_1_20220102_164607	0.964395	0.102728	0.994926	0.117296	0.159487	0.0254361
StackedEnsemble_AllModels_2_AutoML_1_20220102_164607	0.964394	0.110413	0.995001	0.153588	0.169942	0.0288803
StackedEnsemble_BestOfFamily_6_AutoML_1_20220102_164607	0.964133	0.114379	0.994459	0.118422	0.174695	0.0305182
StackedEnsemble_BestOfFamily_2_AutoML_1_20220102_164607	0.964105	0.115202	0.995024	0.137817	0.175215	0.0307003
GBM_1_AutoML_1_20220102_164607	0.962981	0.116233	0.994904	0.131985	0.174924	0.0305985
StackedEnsemble_AllModels_1_AutoML_1_20220102_164607	0.962325	0.111576	0.994611	0.159278	0.169842	0.0288463
StackedEnsemble_BestOfFamily_1_AutoML_1_20220102_164607	0.961039	0.119349	0.99458	0.138349	0.177415	0.0314761
XRT_1_AutoML_1_20220102_164607	0.958397	0.13579	0.99343	0.111688	0.181326	0.0328792
StackedEnsemble_AllModels_7_AutoML_1_20220102_164607	0.957896	0.154948	0.994367	0.146885	0.204323	0.0417478
DeepLearning_1_AutoML_1_20220102_164607	0.957495	0.141323	0.992749	0.114809	0.17772	0.0315844
GBM_5_AutoML_1_20220102_164607	0.957194	0.115202	0.993644	0.133154	0.169553	0.0287482
StackedEnsemble_AllModels_6_AutoML_1_20220102_164607	0.956356	0.121639	0.992706	0.129231	0.178738	0.0319474
GBM_4_AutoML_1_20220102_164607	0.955373	0.119211	0.993436	0.122938	0.17196	0.0295701
DeepLearning_grid_3_AutoML_1_20220102_164607_model_1	0.954893	0.259796	0.992928	0.149066	0.207677	0.0431297
GBM_grid_1_AutoML_1_20220102_164607_model_2	0.954069	0.118124	0.993019	0.140728	0.174282	0.030374
DRF_1_AutoML_1_20220102_164607	0.95365	0.140688	0.993039	0.149999	0.18639	0.0347414
DeepLearning_grid_2_AutoML_1_20220102_164607_model_1	0.952917	0.234338	0.992485	0.1548	0.201	0.0404012
DeepLearning_grid_1_AutoML_1_20220102_164607_model_1	0.929886	0.434231	0.988346	0.160096	0.210986	0.044515
GLM_1_AutoML_1_20220102_164607	0.905408	0.179117	0.986687	0.251175	0.218635	0.0478014
