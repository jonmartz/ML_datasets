AutoML progress: |
13:23:02.49: Fold column FOLD will be used for cross-validation. nfolds parameter will be ignored.
13:23:02.227: _train param, Dropping bad and constant columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]

█████████████████████████████████████████████████████████
13:39:48.517: _train param, Dropping bad and constant columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]

█████
14:02:49.781: _train param, Dropping bad and constant columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


14:20:54.14: _train param, Dropping unused columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


14:21:06.23: _train param, Dropping bad and constant columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]

█
14:35:18.178: _train param, Dropping bad and constant columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


14:42:34.274: _train param, Dropping bad and constant columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


14:52:40.419: _train param, Dropping bad and constant columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


15:02:20.524: _train param, Dropping bad and constant columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


15:13:14.654: _train param, Dropping unused columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


15:13:26.688: _train param, Dropping unused columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


15:13:40.700: _train param, Dropping bad and constant columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


15:23:21.806: _train param, Dropping bad and constant columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


15:31:02.922: _train param, Dropping bad and constant columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


15:37:45.4: _train param, Dropping bad and constant columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


15:43:04.76: _train param, Dropping unused columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


15:43:17.92: _train param, Dropping unused columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


16:55:00.924: _train param, Dropping unused columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


16:55:12.938: _train param, Dropping unused columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


17:26:19.277: _train param, Dropping unused columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


17:26:41.317: _train param, Dropping unused columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


17:27:53.353: _train param, Dropping unused columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


17:28:49.395: _train param, Dropping unused columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


17:31:14.456: _train param, Dropping unused columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


17:33:01.488: _train param, Dropping unused columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


17:35:00.546: _train param, Dropping unused columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]

| (done) 100%
Model Details
=============
H2OXGBoostEstimator :  XGBoost
Model Key:  XGBoost_grid_1_AutoML_1_20220106_132301_model_2


Model Summary:
number_of_trees
0		66.0


ModelMetricsBinomial: xgboost
** Reported on train data. **

MSE: 0.0011997538452101408
RMSE: 0.0346374630308015
LogLoss: 0.0061692632083987
Mean Per-Class Error: 0.004136962110923157
AUC: 0.9999499097066977
AUCPR: 0.9999943287398211
Gini: 0.9998998194133955

Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.543215254942576:
Confirmed	Rejected	Error	Rate
0	Confirmed	10018.0	80.0	0.0079	(80.0/10098.0)
1	Rejected	32.0	90990.0	0.0004	(32.0/91022.0)
2	Total	10050.0	91070.0	0.0011	(112.0/101120.0)

Maximum Metrics: Maximum metrics at their respective thresholds
metric	threshold	value	idx
0	max f1	0.543215	0.999385	205.0
1	max f2	0.486104	0.999587	215.0
2	max f0point5	0.745329	0.999411	164.0
3	max accuracy	0.543215	0.998892	205.0
4	max precision	0.999958	1.000000	0.0
5	max recall	0.028308	1.000000	356.0
6	max specificity	0.999958	1.000000	0.0
7	max absolute_mcc	0.543215	0.993830	205.0
8	max min_per_class_accuracy	0.818334	0.997425	143.0
9	max mean_per_class_accuracy	0.745329	0.997564	164.0
10	max tns	0.999958	10098.000000	0.0
11	max fns	0.999958	76292.000000	0.0
12	max fps	0.000204	10098.000000	399.0
13	max tps	0.028308	91022.000000	356.0
14	max tnr	0.999958	1.000000	0.0
15	max fnr	0.999958	0.838171	0.0
16	max fpr	0.000204	1.000000	399.0
17	max tpr	0.028308	1.000000	356.0

Gains/Lift Table: Avg response rate: 90.01 %, avg score: 90.02 %
group	cumulative_data_fraction	lower_threshold	lift	cumulative_lift	response_rate	score	cumulative_response_rate	cumulative_score	capture_rate	cumulative_capture_rate	gain	cumulative_gain	kolmogorov_smirnov
0	1	0.010067	0.999977	1.110940	1.110940	1.000000	0.999982	1.000000	0.999982	0.011184	0.011184	11.094021	11.094021	0.011184
1	2	0.020055	0.999974	1.110940	1.110940	1.000000	0.999975	1.000000	0.999978	0.011096	0.022280	11.094021	11.094021	0.022280
2	3	0.030202	0.999970	1.110940	1.110940	1.000000	0.999972	1.000000	0.999976	0.011272	0.033552	11.094021	11.094021	0.033552
3	4	0.040131	0.999967	1.110940	1.110940	1.000000	0.999969	1.000000	0.999974	0.011030	0.044583	11.094021	11.094021	0.044583
4	5	0.050049	0.999964	1.110940	1.110940	1.000000	0.999966	1.000000	0.999973	0.011019	0.055602	11.094021	11.094021	0.055602
5	6	0.100148	0.999952	1.110940	1.110940	1.000000	0.999958	1.000000	0.999965	0.055657	0.111259	11.094021	11.094021	0.111259
6	7	0.150326	0.999938	1.110940	1.110940	1.000000	0.999945	1.000000	0.999959	0.055745	0.167004	11.094021	11.094021	0.167004
7	8	0.200267	0.999923	1.110940	1.110940	1.000000	0.999931	1.000000	0.999952	0.055481	0.222485	11.094021	11.094021	0.222485
8	9	0.300049	0.999886	1.110940	1.110940	1.000000	0.999906	1.000000	0.999936	0.110852	0.333337	11.094021	11.094021	0.333337
9	10	0.400069	0.999825	1.110940	1.110940	1.000000	0.999858	1.000000	0.999917	0.111116	0.444453	11.094021	11.094021	0.444453
10	11	0.500059	0.999722	1.110940	1.110940	1.000000	0.999777	1.000000	0.999889	0.111083	0.555536	11.094021	11.094021	0.555536
11	12	0.600010	0.999549	1.110940	1.110940	1.000000	0.999646	1.000000	0.999848	0.111039	0.666575	11.094021	11.094021	0.666575
12	13	0.700030	0.999169	1.110940	1.110940	1.000000	0.999386	1.000000	0.999782	0.111116	0.777691	11.094021	11.094021	0.777691
13	14	0.800000	0.997766	1.110940	1.110940	1.000000	0.998653	1.000000	0.999641	0.111061	0.888752	11.094021	11.094021	0.888752
14	15	0.900000	0.627161	1.104568	1.110232	0.994264	0.981274	0.999363	0.997600	0.110457	0.999209	10.456813	11.023220	0.993465
15	16	1.000000	0.000069	0.007910	1.000000	0.007120	0.023610	0.900138	0.900201	0.000791	1.000000	-99.208982	0.000000	0.000000


ModelMetricsBinomial: xgboost
** Reported on cross-validation data. **

MSE: 0.023843179273156576
RMSE: 0.15441236761722352
LogLoss: 0.0899250778473484
Mean Per-Class Error: 0.12617008977681962
AUC: 0.9799716758322111
AUCPR: 0.9973937690672128
Gini: 0.9599433516644222

Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.34385595056745744:
Confirmed	Rejected	Error	Rate
0	Confirmed	7609.0	2489.0	0.2465	(2489.0/10098.0)
1	Rejected	533.0	90489.0	0.0059	(533.0/91022.0)
2	Total	8142.0	92978.0	0.0299	(3022.0/101120.0)

Maximum Metrics: Maximum metrics at their respective thresholds
metric	threshold	value	idx
0	max f1	0.343856	0.983576	275.0
1	max f2	0.144050	0.991321	324.0
2	max f0point5	0.836364	0.982451	124.0
3	max accuracy	0.343856	0.970115	275.0
4	max precision	0.999883	0.999849	0.0
5	max recall	0.001601	1.000000	398.0
6	max specificity	0.999883	0.999802	0.0
7	max absolute_mcc	0.358679	0.823864	272.0
8	max min_per_class_accuracy	0.944652	0.930085	68.0
9	max mean_per_class_accuracy	0.920391	0.933307	84.0
10	max tns	0.999883	10096.000000	0.0
11	max fns	0.999883	77794.000000	0.0
12	max fps	0.000626	10098.000000	399.0
13	max tps	0.001601	91022.000000	398.0
14	max tnr	0.999883	0.999802	0.0
15	max fnr	0.999883	0.854672	0.0
16	max fpr	0.000626	1.000000	399.0
17	max tpr	0.001601	1.000000	398.0

Gains/Lift Table: Avg response rate: 90.01 %, avg score: 90.30 %
group	cumulative_data_fraction	lower_threshold	lift	cumulative_lift	response_rate	score	cumulative_response_rate	cumulative_score	capture_rate	cumulative_capture_rate	gain	cumulative_gain	kolmogorov_smirnov
0	1	0.010047	0.999968	1.110940	1.110940	1.000000	0.999978	1.000000	0.999978	0.011162	0.011162	11.094021	11.094021	0.011162
1	2	0.020016	0.999951	1.110940	1.110940	1.000000	0.999959	1.000000	0.999969	0.011074	0.022236	11.094021	11.094021	0.022236
2	3	0.030162	0.999937	1.110940	1.110940	1.000000	0.999944	1.000000	0.999960	0.011272	0.033508	11.094021	11.094021	0.033508
3	4	0.040091	0.999925	1.110940	1.110940	1.000000	0.999931	1.000000	0.999953	0.011030	0.044539	11.094021	11.094021	0.044539
4	5	0.050069	0.999912	1.110940	1.110940	1.000000	0.999918	1.000000	0.999946	0.011085	0.055624	11.094021	11.094021	0.055624
5	6	0.100099	0.999852	1.110940	1.110940	1.000000	0.999882	1.000000	0.999914	0.055580	0.111204	11.094021	11.094021	0.111204
6	7	0.150049	0.999789	1.110940	1.110940	1.000000	0.999821	1.000000	0.999883	0.055492	0.166696	11.094021	11.094021	0.166696
7	8	0.200069	0.999716	1.109842	1.110666	0.999011	0.999754	0.999753	0.999851	0.055514	0.222210	10.984201	11.066565	0.221715
8	9	0.300000	0.999537	1.110391	1.110574	0.999505	0.999628	0.999670	0.999777	0.110962	0.333172	11.039051	11.057400	0.332182
9	10	0.400040	0.999260	1.109183	1.110226	0.998418	0.999409	0.999357	0.999685	0.110962	0.444134	10.918309	11.022617	0.441560
10	11	0.500000	0.998789	1.108962	1.109973	0.998219	0.999047	0.999130	0.999557	0.110852	0.554987	10.896189	10.997341	0.550629
11	12	0.600000	0.997911	1.103469	1.108889	0.993275	0.998410	0.998154	0.999366	0.110347	0.665334	10.346949	10.888943	0.654242
12	13	0.700000	0.995255	1.095340	1.106954	0.985957	0.996894	0.996412	0.999013	0.109534	0.774868	9.533959	10.695373	0.749714
13	14	0.800000	0.980272	1.086001	1.104335	0.977551	0.989996	0.994054	0.997886	0.108600	0.883468	8.600119	10.433467	0.835835
14	15	0.900000	0.655054	0.974160	1.089871	0.876879	0.900171	0.981035	0.987029	0.097416	0.980884	-2.583991	8.987082	0.809959
15	16	1.000000	0.000038	0.191163	1.000000	0.172073	0.146571	0.900138	0.902983	0.019116	1.000000	-80.883742	0.000000	0.000000


Cross-Validation Metrics Summary:
mean	sd	cv_1_valid	cv_2_valid	cv_3_valid	cv_4_valid	cv_5_valid	cv_6_valid	cv_7_valid	cv_8_valid	cv_9_valid	cv_10_valid
0	accuracy	0.980093	0.012454	0.992809	0.984001	0.988935	0.983741	0.969118	0.979709	0.985260	0.950619	0.990077	0.976658
1	auc	0.981087	0.023191	0.993470	0.992544	0.967064	0.996481	0.920242	0.978289	0.992162	0.985226	0.993887	0.991503
2	err	0.019907	0.012454	0.007191	0.015999	0.011065	0.016259	0.030882	0.020291	0.014740	0.049381	0.009923	0.023342
3	err_count	190.300000	105.673550	116.000000	218.000000	99.000000	145.000000	278.000000	180.000000	132.000000	439.000000	88.000000	208.000000
4	f0point5	0.986082	0.011476	0.998036	0.988273	0.993366	0.991880	0.976186	0.983541	0.991342	0.958606	0.994060	0.985530
5	f1	0.988256	0.009067	0.996332	0.991195	0.994294	0.990238	0.983539	0.989342	0.991570	0.964905	0.994769	0.986382
6	f2	0.990460	0.007340	0.994634	0.994134	0.995223	0.988600	0.991003	0.995211	0.991798	0.971288	0.995479	0.987235
7	lift_top_group	1.127639	0.124265	1.017278	1.106186	1.033022	1.197529	1.055907	1.060998	1.144263	1.437116	1.055589	1.168502
8	logloss	0.092915	0.058989	0.031619	0.121762	0.044565	0.092657	0.157101	0.061606	0.063808	0.211542	0.030316	0.114173
9	max_per_class_error	0.151399	0.118963	0.047445	0.129969	0.220280	0.035350	0.368976	0.339216	0.061116	0.106509	0.115632	0.089494
10	mcc	0.864873	0.064484	0.823150	0.905121	0.813720	0.941759	0.750544	0.795694	0.932960	0.882255	0.898730	0.904797
11	mean_per_class_accuracy	0.920274	0.057866	0.973030	0.933067	0.887782	0.976081	0.813533	0.829974	0.965417	0.934541	0.940161	0.949155
12	mean_per_class_error	0.079726	0.057866	0.026970	0.066933	0.112218	0.023919	0.186467	0.170026	0.034583	0.065459	0.059839	0.050845
13	mse	0.024513	0.015362	0.008256	0.035020	0.010368	0.031228	0.030723	0.015991	0.016000	0.055720	0.008249	0.033576
14	pr_auc	0.997617	0.002982	0.999868	0.999137	0.998550	0.999297	0.991593	0.998458	0.998745	0.992502	0.999581	0.998440
15	precision	0.984649	0.013270	0.999176	0.986334	0.992749	0.992979	0.971345	0.979712	0.991190	0.954452	0.993587	0.984963
16	r2	0.694948	0.116211	0.505494	0.596440	0.664961	0.773284	0.550317	0.704892	0.854785	0.736734	0.834645	0.727927
17	recall	0.991947	0.006865	0.993505	0.996103	0.995843	0.987512	0.996042	0.999163	0.991950	0.975590	0.995953	0.987805
18	rmse	0.149487	0.049064	0.090865	0.187137	0.101821	0.176714	0.175279	0.126454	0.126490	0.236050	0.090825	0.183238
19	specificity	0.848601	0.118963	0.952555	0.870031	0.779720	0.964650	0.631024	0.660784	0.938884	0.893491	0.884368	0.910506

Scoring History:
timestamp	duration	number_of_trees	training_rmse	training_logloss	training_auc	training_pr_auc	training_lift	training_classification_error
0		2022-01-06 16:11:51	28 min 18.262 sec	0.0	0.500000	0.693147	0.500000	0.900138	1.000000	0.099862
1		2022-01-06 16:12:01	28 min 27.973 sec	5.0	0.136140	0.131908	0.989478	0.997803	1.108663	0.008683
2		2022-01-06 16:12:09	28 min 35.887 sec	10.0	0.082765	0.048210	0.991810	0.998207	1.108938	0.007358
3		2022-01-06 16:12:16	28 min 43.810 sec	15.0	0.070266	0.027019	0.997935	0.999678	1.110940	0.005795
4		2022-01-06 16:12:24	28 min 51.184 sec	20.0	0.062559	0.018761	0.999157	0.999894	1.110940	0.004668
5		2022-01-06 16:12:31	28 min 58.211 sec	25.0	0.056289	0.014645	0.999448	0.999931	1.110940	0.003748
6		2022-01-06 16:12:38	29 min 5.549 sec	30.0	0.051898	0.012320	0.999645	0.999958	1.110940	0.003085
7		2022-01-06 16:12:46	29 min 12.907 sec	35.0	0.048479	0.010791	0.999735	0.999969	1.110940	0.002621
8		2022-01-06 16:12:53	29 min 20.295 sec	40.0	0.045521	0.009611	0.999803	0.999977	1.110940	0.002284
9		2022-01-06 16:13:00	29 min 27.743 sec	45.0	0.042862	0.008691	0.999844	0.999982	1.110940	0.001948
10		2022-01-06 16:13:07	29 min 34.816 sec	50.0	0.040469	0.007919	0.999887	0.999987	1.110940	0.001721
11		2022-01-06 16:13:14	29 min 41.468 sec	55.0	0.038399	0.007246	0.999914	0.999990	1.110940	0.001454
12		2022-01-06 16:13:21	29 min 48.560 sec	60.0	0.036614	0.006728	0.999933	0.999992	1.110940	0.001276
13		2022-01-06 16:13:29	29 min 55.961 sec	65.0	0.034868	0.006247	0.999947	0.999994	1.110940	0.001127
14		2022-01-06 16:13:31	29 min 58.145 sec	66.0	0.034637	0.006169	0.999950	0.999994	1.110940	0.001108

Variable Importances:
variable	relative_importance	scaled_importance	percentage
0	C4	18385.767578	1.000000	0.218505
1	C14.F	8368.852539	0.455181	0.099459
2	C1.F	6946.018555	0.377793	0.082550
3	C19	5588.409668	0.303953	0.066415
4	C77.F	3822.613770	0.207912	0.045430
5	C23	3585.969727	0.195041	0.042617
6	C164.F	2695.598877	0.146613	0.032036
7	C70	2595.679932	0.141179	0.030848
8	C109	2525.812256	0.137379	0.030018
9	C74	1960.928589	0.106655	0.023305
10	C15	1865.930176	0.101488	0.022176
11	C22	1657.359131	0.090144	0.019697
12	C29	1530.076294	0.083221	0.018184
13	C78	1343.720703	0.073085	0.015969
14	C71	1287.581055	0.070031	0.015302
15	C30	1274.852661	0.069339	0.015151
16	C80	1083.569946	0.058935	0.012878
17	C111	913.025146	0.049659	0.010851
18	C55.F	834.645203	0.045396	0.009919
19	C6	781.702515	0.042517	0.009290

See the whole table with table.as_data_frame()


LEADERBOARD:
model_id	auc	logloss	aucpr	mean_per_class_error	rmse	mse
XGBoost_grid_1_AutoML_1_20220106_132301_model_2	0.979972	0.0899251	0.997394	0.12617	0.154412	0.0238432
XGBoost_grid_1_AutoML_1_20220106_132301_model_3	0.978723	0.0998631	0.997191	0.138747	0.16277	0.0264941
StackedEnsemble_BestOfFamily_7_AutoML_1_20220106_132301	0.978444	0.0869832	0.997097	0.0958311	0.147305	0.0216987
XGBoost_3_AutoML_1_20220106_132301	0.977391	0.0931148	0.997036	0.119978	0.157367	0.0247644
XGBoost_2_AutoML_1_20220106_132301	0.977065	0.0985834	0.996989	0.127086	0.160974	0.0259127
StackedEnsemble_BestOfFamily_4_AutoML_1_20220106_132301	0.977006	0.0865245	0.996829	0.119008	0.149412	0.0223241
StackedEnsemble_AllModels_3_AutoML_1_20220106_132301	0.975594	0.0884135	0.996585	0.120279	0.151369	0.0229127
XGBoost_grid_1_AutoML_1_20220106_132301_model_1	0.975071	0.101518	0.996657	0.135352	0.163245	0.026649
StackedEnsemble_AllModels_4_AutoML_1_20220106_132301	0.974858	0.0889665	0.996436	0.120697	0.151841	0.0230556
XGBoost_1_AutoML_1_20220106_132301	0.974053	0.101337	0.996451	0.130268	0.164264	0.0269827
StackedEnsemble_AllModels_2_AutoML_1_20220106_132301	0.974033	0.0885407	0.996224	0.128395	0.150768	0.0227309
StackedEnsemble_BestOfFamily_6_AutoML_1_20220106_132301	0.97393	0.100267	0.996269	0.118278	0.163999	0.0268956
StackedEnsemble_BestOfFamily_3_AutoML_1_20220106_132301	0.973928	0.0869514	0.996157	0.118248	0.148421	0.0220287
GBM_grid_1_AutoML_1_20220106_132301_model_1	0.973649	0.0926359	0.996432	0.107061	0.152243	0.0231779
StackedEnsemble_BestOfFamily_5_AutoML_1_20220106_132301	0.972631	0.114311	0.996115	0.127107	0.177638	0.0315554
StackedEnsemble_AllModels_7_AutoML_1_20220106_132301	0.972382	0.10274	0.996096	0.0830195	0.164134	0.0269399
StackedEnsemble_AllModels_5_AutoML_1_20220106_132301	0.972066	0.110888	0.996069	0.124573	0.169515	0.0287355
StackedEnsemble_AllModels_6_AutoML_1_20220106_132301	0.971754	0.102625	0.994854	0.145906	0.16758	0.0280832
StackedEnsemble_BestOfFamily_2_AutoML_1_20220106_132301	0.971532	0.0973314	0.995918	0.12732	0.160061	0.0256194
GBM_1_AutoML_1_20220106_132301	0.971506	0.0952715	0.99602	0.104289	0.15565	0.024227
StackedEnsemble_AllModels_1_AutoML_1_20220106_132301	0.971213	0.0977	0.995873	0.127804	0.160321	0.0257029
StackedEnsemble_BestOfFamily_1_AutoML_1_20220106_132301	0.969937	0.0964747	0.995613	0.129082	0.156735	0.024566
GBM_2_AutoML_1_20220106_132301	0.969672	0.103801	0.995697	0.138593	0.166088	0.0275851
GBM_grid_1_AutoML_1_20220106_132301_model_2	0.96809	0.100089	0.99525	0.103818	0.160333	0.0257065
GBM_4_AutoML_1_20220106_132301	0.967611	0.10016	0.995195	0.135904	0.160185	0.0256592
GBM_3_AutoML_1_20220106_132301	0.964831	0.107022	0.994818	0.142081	0.167977	0.0282164
DRF_1_AutoML_1_20220106_132301	0.963375	0.123751	0.993798	0.127132	0.174555	0.0304695
XRT_1_AutoML_1_20220106_132301	0.963238	0.128515	0.993407	0.114025	0.175201	0.0306955
GBM_5_AutoML_1_20220106_132301	0.962265	0.115203	0.994373	0.145052	0.173739	0.0301851
DeepLearning_1_AutoML_1_20220106_132301	0.960717	0.116564	0.993327	0.107583	0.162165	0.0262974
DeepLearning_grid_3_AutoML_1_20220106_132301_model_1	0.95561	0.215824	0.992475	0.142925	0.191332	0.0366078
DeepLearning_grid_2_AutoML_1_20220106_132301_model_1	0.954205	0.342632	0.992072	0.146309	0.202735	0.0411015
DeepLearning_grid_1_AutoML_1_20220106_132301_model_1	0.947299	0.302122	0.990634	0.14241	0.198825	0.0395316
GLM_1_AutoML_1_20220106_132301	0.916175	0.159346	0.988948	0.21862	0.206807	0.0427692
