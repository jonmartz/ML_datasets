AutoML progress: |
12:19:53.736: Fold column FOLD will be used for cross-validation. nfolds parameter will be ignored.
12:19:53.863: _train param, Dropping bad and constant columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]

████████████████████████████████████████████████████████
12:36:29.225: _train param, Dropping bad and constant columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]

██████
13:01:30.531: _train param, Dropping bad and constant columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


13:19:02.798: _train param, Dropping unused columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


13:19:14.811: _train param, Dropping bad and constant columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]

█
13:34:12.952: _train param, Dropping bad and constant columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


13:41:40.95: _train param, Dropping bad and constant columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


13:50:03.212: _train param, Dropping bad and constant columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


13:58:57.326: _train param, Dropping bad and constant columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


14:08:38.480: _train param, Dropping unused columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


14:08:50.494: _train param, Dropping unused columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


14:09:03.506: _train param, Dropping bad and constant columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


14:19:12.619: _train param, Dropping bad and constant columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


14:27:17.741: _train param, Dropping bad and constant columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


14:34:33.837: _train param, Dropping bad and constant columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


14:39:49.900: _train param, Dropping unused columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


14:40:01.934: _train param, Dropping unused columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


15:52:08.960: _train param, Dropping unused columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


16:24:53.320: _train param, Dropping unused columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


16:25:15.342: _train param, Dropping unused columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


16:26:33.382: _train param, Dropping unused columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


16:27:30.412: _train param, Dropping unused columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


16:30:12.456: _train param, Dropping unused columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


16:32:02.497: _train param, Dropping unused columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


16:33:44.560: _train param, Dropping unused columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]

| (done) 100%
Model Details
=============
H2OXGBoostEstimator :  XGBoost
Model Key:  XGBoost_2_AutoML_1_20220102_121953


Model Summary:
number_of_trees
0		53.0


ModelMetricsBinomial: xgboost
** Reported on train data. **

MSE: 0.002406075727680734
RMSE: 0.04905176579574617
LogLoss: 0.010854922775138214
Mean Per-Class Error: 0.00824621572735431
AUC: 0.9997833199914286
AUCPR: 0.9999756744536188
Gini: 0.9995666399828571

Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5901565949122111:
Confirmed	Rejected	Error	Rate
0	Confirmed	9857.0	152.0	0.0152	(152.0/10009.0)
1	Rejected	119.0	90992.0	0.0013	(119.0/91111.0)
2	Total	9976.0	91144.0	0.0027	(271.0/101120.0)

Maximum Metrics: Maximum metrics at their respective thresholds
metric	threshold	value	idx
0	max f1	0.590157	0.998513	194.0
1	max f2	0.355360	0.998967	243.0
2	max f0point5	0.725784	0.998609	165.0
3	max accuracy	0.590157	0.997320	194.0
4	max precision	0.999939	1.000000	0.0
5	max recall	0.027135	1.000000	361.0
6	max specificity	0.999939	1.000000	0.0
7	max absolute_mcc	0.590157	0.984955	194.0
8	max min_per_class_accuracy	0.866078	0.994005	124.0
9	max mean_per_class_accuracy	0.839817	0.994188	134.0
10	max tns	0.999939	10009.000000	0.0
11	max fns	0.999939	74622.000000	0.0
12	max fps	0.000207	10009.000000	399.0
13	max tps	0.027135	91111.000000	361.0
14	max tnr	0.999939	1.000000	0.0
15	max fnr	0.999939	0.819023	0.0
16	max fpr	0.000207	1.000000	399.0
17	max tpr	0.027135	1.000000	361.0

Gains/Lift Table: Avg response rate: 90.10 %, avg score: 90.10 %
group	cumulative_data_fraction	lower_threshold	lift	cumulative_lift	response_rate	score	cumulative_response_rate	cumulative_score	capture_rate	cumulative_capture_rate	gain	cumulative_gain	kolmogorov_smirnov
0	1	0.010097	0.999977	1.109855	1.109855	1.000000	0.999982	1.000000	0.999982	0.011206	0.011206	10.985501	10.985501	0.011206
1	2	0.020085	0.999970	1.109855	1.109855	1.000000	0.999973	1.000000	0.999977	0.011085	0.022291	10.985501	10.985501	0.022291
2	3	0.030142	0.999964	1.109855	1.109855	1.000000	0.999967	1.000000	0.999974	0.011162	0.033454	10.985501	10.985501	0.033454
3	4	0.040220	0.999959	1.109855	1.109855	1.000000	0.999961	1.000000	0.999971	0.011184	0.044638	10.985501	10.985501	0.044638
4	5	0.050129	0.999954	1.109855	1.109855	1.000000	0.999957	1.000000	0.999968	0.010998	0.055635	10.985501	10.985501	0.055635
5	6	0.100020	0.999932	1.109855	1.109855	1.000000	0.999943	1.000000	0.999955	0.055372	0.111007	10.985501	10.985501	0.111007
6	7	0.150198	0.999910	1.109855	1.109855	1.000000	0.999921	1.000000	0.999944	0.055690	0.166698	10.985501	10.985501	0.166698
7	8	0.200099	0.999883	1.109855	1.109855	1.000000	0.999896	1.000000	0.999932	0.055383	0.222081	10.985501	10.985501	0.222081
8	9	0.300099	0.999804	1.109855	1.109855	1.000000	0.999846	1.000000	0.999903	0.110986	0.333066	10.985501	10.985501	0.333066
9	10	0.400000	0.999688	1.109855	1.109855	1.000000	0.999752	1.000000	0.999866	0.110876	0.443942	10.985501	10.985501	0.443942
10	11	0.500010	0.999504	1.109855	1.109855	1.000000	0.999603	1.000000	0.999813	0.110996	0.554938	10.985501	10.985501	0.554938
11	12	0.600010	0.999192	1.109855	1.109855	1.000000	0.999367	1.000000	0.999739	0.110986	0.665924	10.985501	10.985501	0.665924
12	13	0.700000	0.998479	1.109855	1.109855	1.000000	0.998892	1.000000	0.999618	0.110975	0.776899	10.985501	10.985501	0.776899
13	14	0.800000	0.996020	1.109635	1.109828	0.999802	0.997568	0.999975	0.999362	0.110964	0.887862	10.963550	10.982757	0.887662
14	15	0.900000	0.704290	1.098331	1.108550	0.989616	0.975579	0.998824	0.996719	0.109833	0.997695	9.833061	10.855013	0.987005
15	16	1.000000	0.000015	0.023049	1.000000	0.020767	0.039547	0.901019	0.901002	0.002305	1.000000	-97.695119	0.000000	0.000000


ModelMetricsBinomial: xgboost
** Reported on cross-validation data. **

MSE: 0.02828598291114059
RMSE: 0.1681843717803191
LogLoss: 0.10798482556618443
Mean Per-Class Error: 0.13297589851521047
AUC: 0.9717824591490382
AUCPR: 0.9961852894798354
Gini: 0.9435649182980763

Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.45748502810796104:
Confirmed	Rejected	Error	Rate
0	Confirmed	7452.0	2557.0	0.2555	(2557.0/10009.0)
1	Rejected	955.0	90156.0	0.0105	(955.0/91111.0)
2	Total	8407.0	92713.0	0.0347	(3512.0/101120.0)

Maximum Metrics: Maximum metrics at their respective thresholds
metric	threshold	value	idx
0	max f1	0.457485	0.980895	249.0
1	max f2	0.186153	0.988156	318.0
2	max f0point5	0.834845	0.979561	131.0
3	max accuracy	0.457485	0.965269	249.0
4	max precision	0.999873	0.999707	0.0
5	max recall	0.000354	1.000000	399.0
6	max specificity	0.999873	0.999700	0.0
7	max absolute_mcc	0.457485	0.793989	249.0
8	max min_per_class_accuracy	0.958275	0.919143	66.0
9	max mean_per_class_accuracy	0.957158	0.919591	67.0
10	max tns	0.999873	10006.000000	0.0
11	max fns	0.999873	80864.000000	0.0
12	max fps	0.000354	10009.000000	399.0
13	max tps	0.000354	91111.000000	399.0
14	max tnr	0.999873	0.999700	0.0
15	max fnr	0.999873	0.887533	0.0
16	max fpr	0.000354	1.000000	399.0
17	max tpr	0.000354	1.000000	399.0

Gains/Lift Table: Avg response rate: 90.10 %, avg score: 90.55 %
group	cumulative_data_fraction	lower_threshold	lift	cumulative_lift	response_rate	score	cumulative_response_rate	cumulative_score	capture_rate	cumulative_capture_rate	gain	cumulative_gain	kolmogorov_smirnov
0	1	0.010107	0.999958	1.108769	1.108769	0.999022	0.999973	0.999022	0.999973	0.011206	0.011206	10.876905	10.876905	0.011106
1	2	0.020095	0.999937	1.108756	1.108763	0.999010	0.999947	0.999016	0.999960	0.011074	0.022281	10.875615	10.876264	0.022081
2	3	0.030004	0.999919	1.109855	1.109123	1.000000	0.999928	0.999341	0.999950	0.010998	0.033278	10.985501	10.912340	0.033078
3	4	0.040051	0.999903	1.109855	1.109307	1.000000	0.999911	0.999506	0.999940	0.011151	0.044429	10.985501	10.930694	0.044230
4	5	0.050000	0.999886	1.109855	1.109416	1.000000	0.999894	0.999604	0.999931	0.011041	0.055471	10.985501	10.941599	0.055271
5	6	0.100010	0.999797	1.109855	1.109636	1.000000	0.999842	0.999802	0.999886	0.055504	0.110975	10.985501	10.963552	0.110775
6	7	0.150010	0.999700	1.108977	1.109416	0.999209	0.999749	0.999604	0.999841	0.055449	0.166423	10.897696	10.941602	0.165824
7	8	0.200010	0.999587	1.109196	1.109361	0.999407	0.999645	0.999555	0.999792	0.055460	0.221883	10.919647	10.936113	0.220984
8	9	0.300020	0.999297	1.108209	1.108977	0.998517	0.999450	0.999209	0.999678	0.110832	0.332715	10.820883	10.897702	0.330317
9	10	0.400000	0.998869	1.106452	1.108346	0.996934	0.999101	0.998640	0.999534	0.110623	0.443338	10.645190	10.834586	0.437843
10	11	0.500000	0.998080	1.101184	1.106914	0.992188	0.998520	0.997350	0.999331	0.110118	0.553457	10.118427	10.691355	0.540069
11	12	0.600010	0.996512	1.099539	1.105684	0.990705	0.997361	0.996242	0.999003	0.109965	0.663422	9.953895	10.568434	0.640642
12	13	0.700000	0.993248	1.098110	1.104602	0.989417	0.995193	0.995267	0.998458	0.109800	0.773222	9.810993	10.460239	0.739752
13	14	0.800000	0.977949	1.083733	1.101994	0.976464	0.987925	0.992917	0.997142	0.108373	0.881595	8.373303	10.199372	0.824347
14	15	0.900198	0.678782	0.960881	1.086287	0.865772	0.902145	0.978765	0.986568	0.096278	0.977873	-3.911882	8.628699	0.784747
15	16	1.000000	0.000005	0.221707	1.000000	0.199762	0.174139	0.901019	0.905486	0.022127	1.000000	-77.829293	0.000000	0.000000


Cross-Validation Metrics Summary:
mean	sd	cv_1_valid	cv_2_valid	cv_3_valid	cv_4_valid	cv_5_valid	cv_6_valid	cv_7_valid	cv_8_valid	cv_9_valid	cv_10_valid
0	accuracy	0.975435	0.016567	0.992499	0.982754	0.989941	0.981498	0.971006	0.980047	0.974874	0.937458	0.985792	0.958478
1	auc	0.973818	0.031775	0.989626	0.983753	0.987593	0.994703	0.885203	0.973924	0.987635	0.979195	0.978226	0.978318
2	err	0.024565	0.016567	0.007501	0.017246	0.010059	0.018502	0.028994	0.019953	0.025126	0.062542	0.014208	0.041522
3	err_count	232.600000	139.900920	121.000000	235.000000	90.000000	165.000000	261.000000	177.000000	225.000000	556.000000	126.000000	370.000000
4	f0point5	0.982075	0.014039	0.994570	0.987400	0.994125	0.989510	0.976684	0.984986	0.985438	0.948660	0.989983	0.969390
5	f1	0.985376	0.012117	0.996226	0.990528	0.994813	0.988912	0.984555	0.989506	0.985701	0.955096	0.992521	0.975905
6	f2	0.988717	0.010641	0.997888	0.993676	0.995501	0.988314	0.992555	0.994068	0.985964	0.961620	0.995073	0.982508
7	lift_top_group	1.129320	0.129027	1.009007	1.104214	1.032545	1.197368	1.079894	1.059983	1.138734	1.452377	1.045346	1.173736
8	logloss	0.111485	0.072844	0.042021	0.142473	0.039654	0.097182	0.160547	0.065802	0.082409	0.269900	0.052026	0.162835
9	max_per_class_error	0.243238	0.194335	0.729167	0.142302	0.195035	0.051020	0.366366	0.304781	0.106324	0.125677	0.206250	0.205459
10	mcc	0.807644	0.139233	0.435400	0.895843	0.829976	0.933092	0.767554	0.797081	0.882258	0.852730	0.853795	0.828716
11	mean_per_class_accuracy	0.873864	0.094829	0.634916	0.926742	0.900463	0.968448	0.815797	0.846176	0.939907	0.920171	0.895266	0.890751
12	mean_per_class_error	0.126136	0.094829	0.365084	0.073258	0.099537	0.031552	0.184203	0.153824	0.060093	0.079829	0.104734	0.109249
13	mse	0.029015	0.019248	0.011194	0.040815	0.010203	0.031209	0.029112	0.016741	0.021681	0.070516	0.012137	0.046537
14	pr_auc	0.996187	0.004472	0.999901	0.997948	0.999558	0.998824	0.986847	0.998066	0.998079	0.989323	0.997865	0.995465
15	precision	0.979895	0.015476	0.993469	0.985326	0.993667	0.989910	0.971505	0.981996	0.985262	0.944418	0.988298	0.965095
16	r2	0.582014	0.310112	-0.265323	0.522474	0.665754	0.773298	0.575071	0.686418	0.797348	0.671187	0.762932	0.630978
17	recall	0.990965	0.010025	0.998999	0.995786	0.995961	0.987916	0.997961	0.997132	0.986139	0.966019	0.996781	0.986960
18	rmse	0.162420	0.054103	0.105801	0.202026	0.101010	0.176660	0.170622	0.129387	0.147246	0.265549	0.110169	0.215725
19	specificity	0.756762	0.194335	0.270833	0.857698	0.804965	0.948980	0.633634	0.695219	0.893675	0.874323	0.793750	0.794541

Scoring History:
timestamp	duration	number_of_trees	training_rmse	training_logloss	training_auc	training_pr_auc	training_lift	training_classification_error
0		2022-01-02 13:32:51	13 min 36.751 sec	0.0	0.500000	0.693147	0.500000	0.901019	1.000000	0.098981
1		2022-01-02 13:33:00	13 min 45.890 sec	5.0	0.149249	0.142400	0.980180	0.995999	1.105655	0.013360
2		2022-01-02 13:33:07	13 min 53.092 sec	10.0	0.092357	0.053892	0.993484	0.998908	1.109316	0.009246
3		2022-01-02 13:33:15	14 min 0.255 sec	15.0	0.077877	0.030761	0.997957	0.999743	1.109855	0.006942
4		2022-01-02 13:33:22	14 min 7.425 sec	20.0	0.070600	0.022589	0.998601	0.999819	1.109855	0.006023
5		2022-01-02 13:33:29	14 min 14.450 sec	25.0	0.065875	0.019066	0.999066	0.999888	1.109855	0.005162
6		2022-01-02 13:33:36	14 min 21.576 sec	30.0	0.061836	0.016697	0.999304	0.999919	1.109855	0.004579
7		2022-01-02 13:33:43	14 min 28.705 sec	35.0	0.058305	0.014865	0.999502	0.999943	1.109855	0.004005
8		2022-01-02 13:33:50	14 min 36.026 sec	40.0	0.055751	0.013602	0.999591	0.999953	1.109855	0.003649
9		2022-01-02 13:33:58	14 min 43.220 sec	45.0	0.052605	0.012323	0.999686	0.999964	1.109855	0.003165
10		2022-01-02 13:34:06	14 min 52.052 sec	50.0	0.050398	0.011383	0.999747	0.999971	1.109855	0.002878
11		2022-01-02 13:34:11	14 min 56.675 sec	53.0	0.049052	0.010855	0.999783	0.999976	1.109855	0.002680

Variable Importances:
variable	relative_importance	scaled_importance	percentage
0	C4	14261.819336	1.000000	0.222485
1	C1.F	5846.442871	0.409937	0.091205
2	C14.F	5403.966797	0.378911	0.084302
3	C19	4426.683594	0.310387	0.069057
4	C23	2508.840332	0.175913	0.039138
5	C32	2433.038330	0.170598	0.037956
6	C74	2062.198975	0.144596	0.032170
7	C164.F	1341.058716	0.094031	0.020921
8	C15	1332.049683	0.093400	0.020780
9	C77.F	1188.506470	0.083335	0.018541
10	C80	1004.921631	0.070462	0.015677
11	C30	1004.066956	0.070402	0.015664
12	C77.T	980.865845	0.068776	0.015302
13	C22	902.528076	0.063283	0.014080
14	C71	885.675293	0.062101	0.013817
15	C21	759.472595	0.053252	0.011848
16	C33	718.430603	0.050374	0.011208
17	C70	666.431641	0.046728	0.010396
18	C26	630.759338	0.044227	0.009840
19	C72.F	607.399902	0.042589	0.009475

See the whole table with table.as_data_frame()


LEADERBOARD:
model_id	auc	logloss	aucpr	mean_per_class_error	rmse	mse
XGBoost_2_AutoML_1_20220102_121953	0.971782	0.107985	0.996185	0.132976	0.168184	0.028286
XGBoost_3_AutoML_1_20220102_121953	0.97045	0.11444	0.995978	0.126725	0.175559	0.0308209
XGBoost_grid_1_AutoML_1_20220102_121953_model_3	0.970182	0.111652	0.996069	0.129684	0.172665	0.0298131
XGBoost_grid_1_AutoML_1_20220102_121953_model_2	0.969017	0.109457	0.995664	0.139703	0.169359	0.0286825
XGBoost_1_AutoML_1_20220102_121953	0.967534	0.12192	0.995691	0.128184	0.181685	0.0330093
XGBoost_grid_1_AutoML_1_20220102_121953_model_1	0.967136	0.121059	0.99566	0.149028	0.180591	0.0326132
StackedEnsemble_AllModels_2_AutoML_1_20220102_121953	0.965549	0.115926	0.995098	0.129058	0.176122	0.031019
StackedEnsemble_BestOfFamily_6_AutoML_1_20220102_121953	0.965525	0.132812	0.995285	0.127523	0.187374	0.035109
StackedEnsemble_BestOfFamily_3_AutoML_1_20220102_121953	0.964403	0.118713	0.994998	0.13676	0.179101	0.0320771
StackedEnsemble_BestOfFamily_2_AutoML_1_20220102_121953	0.964263	0.115793	0.994942	0.138153	0.176035	0.0309884
StackedEnsemble_AllModels_1_AutoML_1_20220102_121953	0.963951	0.113307	0.994767	0.138529	0.173216	0.0300038
StackedEnsemble_BestOfFamily_4_AutoML_1_20220102_121953	0.9636	0.118842	0.994723	0.110767	0.174998	0.0306243
GBM_1_AutoML_1_20220102_121953	0.963289	0.116026	0.994965	0.107394	0.173922	0.030249
StackedEnsemble_AllModels_4_AutoML_1_20220102_121953	0.963201	0.125597	0.994839	0.137669	0.184563	0.0340634
StackedEnsemble_AllModels_3_AutoML_1_20220102_121953	0.963194	0.12487	0.9948	0.132504	0.183496	0.0336708
StackedEnsemble_AllModels_7_AutoML_1_20220102_121953	0.963061	0.129311	0.994847	0.12094	0.186327	0.0347177
StackedEnsemble_AllModels_6_AutoML_1_20220102_121953	0.962477	0.12357	0.993762	0.145387	0.184264	0.0339531
StackedEnsemble_BestOfFamily_5_AutoML_1_20220102_121953	0.962386	0.116828	0.993732	0.102535	0.175136	0.0306727
GBM_grid_1_AutoML_1_20220102_121953_model_1	0.961584	0.111746	0.994548	0.131077	0.167655	0.028108
StackedEnsemble_BestOfFamily_1_AutoML_1_20220102_121953	0.960874	0.118702	0.99452	0.160024	0.176433	0.0311287
GBM_2_AutoML_1_20220102_121953	0.960367	0.111185	0.994004	0.111615	0.167116	0.0279277
GBM_4_AutoML_1_20220102_121953	0.959785	0.118383	0.994282	0.117288	0.175327	0.0307396
StackedEnsemble_AllModels_5_AutoML_1_20220102_121953	0.959282	0.135529	0.993974	0.147518	0.190908	0.0364459
GBM_grid_1_AutoML_1_20220102_121953_model_2	0.958097	0.121471	0.994034	0.146057	0.180014	0.0324052
XRT_1_AutoML_1_20220102_121953	0.954806	0.142193	0.993306	0.110764	0.187946	0.0353237
GBM_3_AutoML_1_20220102_121953	0.954206	0.1209	0.993177	0.135301	0.176608	0.0311903
DRF_1_AutoML_1_20220102_121953	0.953728	0.136538	0.992153	0.106855	0.182659	0.0333644
DeepLearning_1_AutoML_1_20220102_121953	0.949548	0.180686	0.992524	0.126127	0.191798	0.0367866
GBM_5_AutoML_1_20220102_121953	0.947265	0.126503	0.991859	0.111587	0.175259	0.0307157
DeepLearning_grid_2_AutoML_1_20220102_121953_model_1	0.936517	0.392074	0.990383	0.21469	0.226644	0.0513676
DeepLearning_grid_1_AutoML_1_20220102_121953_model_1	0.935308	0.414842	0.989314	0.170213	0.209681	0.0439663
DeepLearning_grid_3_AutoML_1_20220102_121953_model_1	0.934455	0.283776	0.988905	0.182501	0.218471	0.0477295
GLM_1_AutoML_1_20220102_121953	0.905587	0.173422	0.987373	0.227014	0.214006	0.0457985
