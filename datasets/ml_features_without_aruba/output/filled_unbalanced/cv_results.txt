AutoML progress: |
11:02:09.61: Fold column FOLD will be used for cross-validation. nfolds parameter will be ignored.
11:02:09.209: _train param, Dropping bad and constant columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]

█████████████████████████████████████████████████████████
11:20:09.610: _train param, Dropping bad and constant columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]

█████
11:37:52.855: _train param, Dropping bad and constant columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


11:54:27.122: _train param, Dropping unused columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


11:54:38.139: _train param, Dropping bad and constant columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


12:06:16.304: _train param, Dropping bad and constant columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]

█
12:12:09.378: _train param, Dropping bad and constant columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


12:21:07.492: _train param, Dropping bad and constant columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


12:31:50.664: _train param, Dropping bad and constant columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


12:42:54.827: _train param, Dropping unused columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


12:43:05.843: _train param, Dropping unused columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


12:43:18.856: _train param, Dropping bad and constant columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


12:50:33.965: _train param, Dropping bad and constant columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


12:57:21.71: _train param, Dropping bad and constant columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


13:05:32.198: _train param, Dropping bad and constant columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


13:10:30.299: _train param, Dropping unused columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


13:10:42.333: _train param, Dropping unused columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


14:19:51.526: _train param, Dropping unused columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


14:20:03.553: _train param, Dropping unused columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


14:59:50.125: _train param, Dropping unused columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


15:00:11.151: _train param, Dropping unused columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


15:01:20.187: _train param, Dropping unused columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


15:02:15.231: _train param, Dropping unused columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


15:04:35.301: _train param, Dropping unused columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


15:06:20.361: _train param, Dropping unused columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]


15:08:09.423: _train param, Dropping unused columns: [C97, C98, C89, C18, C106, C105, C138, C149, C137, C102, C101, C123, C122, C121, C150, C90, C93, C94]

| (done) 100%
Model Details
=============
H2OXGBoostEstimator :  XGBoost
Model Key:  XGBoost_grid_1_AutoML_1_20220117_110208_model_3


Model Summary:
number_of_trees
0		62.0


ModelMetricsBinomial: xgboost
** Reported on train data. **

MSE: 0.002669092522992391
RMSE: 0.05166326086294196
LogLoss: 0.01186126321556169
Mean Per-Class Error: 0.009713363802790753
AUC: 0.9996743961618694
AUCPR: 0.9999528124723381
Gini: 0.9993487923237387

Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5654899477958679:
Confirmed	Rejected	Error	Rate
0	Confirmed	9644.0	180.0	0.0183	(180.0/9824.0)
1	Rejected	83.0	75081.0	0.0011	(83.0/75164.0)
2	Total	9727.0	75261.0	0.0031	(263.0/84988.0)

Maximum Metrics: Maximum metrics at their respective thresholds
metric	threshold	value	idx
0	max f1	0.565490	0.998252	211.0
1	max f2	0.316078	0.998913	260.0
2	max f0point5	0.747885	0.998346	169.0
3	max accuracy	0.565490	0.996905	211.0
4	max precision	0.999934	1.000000	0.0
5	max recall	0.007691	1.000000	383.0
6	max specificity	0.999934	1.000000	0.0
7	max absolute_mcc	0.565490	0.984815	211.0
8	max min_per_class_accuracy	0.872298	0.993791	130.0
9	max mean_per_class_accuracy	0.842950	0.994036	141.0
10	max tns	0.999934	9824.000000	0.0
11	max fns	0.999934	66858.000000	0.0
12	max fps	0.000051	9824.000000	399.0
13	max tps	0.007691	75164.000000	383.0
14	max tnr	0.999934	1.000000	0.0
15	max fnr	0.999934	0.889495	0.0
16	max fpr	0.000051	1.000000	399.0
17	max tpr	0.007691	1.000000	383.0

Gains/Lift Table: Avg response rate: 88.44 %, avg score: 88.44 %
group	cumulative_data_fraction	lower_threshold	lift	cumulative_lift	response_rate	score	cumulative_response_rate	cumulative_score	capture_rate	cumulative_capture_rate	gain	cumulative_gain	kolmogorov_smirnov
0	1	0.010001	9.999684e-01	1.130701	1.130701	1.000000	0.999977	1.000000	0.999977	0.011309	0.011309	13.070087	13.070087	0.011309
1	2	0.020062	9.999577e-01	1.130701	1.130701	1.000000	0.999963	1.000000	0.999970	0.011375	0.022684	13.070087	13.070087	0.022684
2	3	0.030063	9.999489e-01	1.130701	1.130701	1.000000	0.999953	1.000000	0.999964	0.011309	0.033992	13.070087	13.070087	0.033992
3	4	0.040170	9.999405e-01	1.130701	1.130701	1.000000	0.999945	1.000000	0.999959	0.011428	0.045421	13.070087	13.070087	0.045421
4	5	0.050113	9.999322e-01	1.130701	1.130701	1.000000	0.999936	1.000000	0.999955	0.011242	0.056663	13.070087	13.070087	0.056663
5	6	0.100108	9.998993e-01	1.130701	1.130701	1.000000	0.999916	1.000000	0.999935	0.056530	0.113192	13.070087	13.070087	0.113192
6	7	0.150327	9.998620e-01	1.130701	1.130701	1.000000	0.999880	1.000000	0.999917	0.056783	0.169975	13.070087	13.070087	0.169975
7	8	0.200064	9.998185e-01	1.130701	1.130701	1.000000	0.999841	1.000000	0.999898	0.056237	0.226212	13.070087	13.070087	0.226212
8	9	0.300007	9.996866e-01	1.130701	1.130701	1.000000	0.999757	1.000000	0.999851	0.113006	0.339218	13.070087	13.070087	0.339218
9	10	0.400056	9.994918e-01	1.130701	1.130701	1.000000	0.999595	1.000000	0.999787	0.113126	0.452344	13.070087	13.070087	0.452344
10	11	0.500024	9.991849e-01	1.130568	1.130674	0.999882	0.999350	0.999976	0.999700	0.113020	0.565364	13.056778	13.067426	0.565262
11	12	0.600002	9.986710e-01	1.130701	1.130679	1.000000	0.998957	0.999980	0.999576	0.113046	0.678410	13.070087	13.067869	0.678308
12	13	0.699993	9.977330e-01	1.130435	1.130644	0.999765	0.998268	0.999950	0.999389	0.113033	0.791443	13.043476	13.064385	0.791137
13	14	0.799995	9.942159e-01	1.130302	1.130601	0.999647	0.996467	0.999912	0.999024	0.113033	0.904476	13.030175	13.060109	0.903865
14	15	0.899998	3.536565e-02	0.955089	1.111099	0.844688	0.848799	0.982664	0.982332	0.095511	0.999987	-4.491099	11.109923	0.865011
15	16	1.000000	2.424032e-07	0.000133	1.000000	0.000118	0.002955	0.884407	0.884392	0.000013	1.000000	-99.986696	0.000000	0.000000


ModelMetricsBinomial: xgboost
** Reported on cross-validation data. **

MSE: 0.029394146503022855
RMSE: 0.1714472120013121
LogLoss: 0.1079812157085264
Mean Per-Class Error: 0.13097125339128146
AUC: 0.9769327869399845
AUCPR: 0.9965022724933849
Gini: 0.9538655738799691

Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.25774751054613215:
Confirmed	Rejected	Error	Rate
0	Confirmed	7324.0	2500.0	0.2545	(2500.0/9824.0)
1	Rejected	561.0	74603.0	0.0075	(561.0/75164.0)
2	Total	7885.0	77103.0	0.036	(3061.0/84988.0)

Maximum Metrics: Maximum metrics at their respective thresholds
metric	threshold	value	idx
0	max f1	0.257748	0.979897	302.0
1	max f2	0.163261	0.988620	328.0
2	max f0point5	0.809421	0.978698	142.0
3	max accuracy	0.257748	0.963983	302.0
4	max precision	0.999885	0.999741	0.0
5	max recall	0.000121	1.000000	399.0
6	max specificity	0.999885	0.999796	0.0
7	max absolute_mcc	0.257748	0.813397	302.0
8	max min_per_class_accuracy	0.933872	0.917752	82.0
9	max mean_per_class_accuracy	0.885168	0.920847	110.0
10	max tns	0.999885	9822.000000	0.0
11	max fns	0.999885	67444.000000	0.0
12	max fps	0.000121	9824.000000	399.0
13	max tps	0.000121	75164.000000	399.0
14	max tnr	0.999885	0.999796	0.0
15	max fnr	0.999885	0.897291	0.0
16	max fpr	0.000121	1.000000	399.0
17	max tpr	0.000121	1.000000	399.0

Gains/Lift Table: Avg response rate: 88.44 %, avg score: 88.34 %
group	cumulative_data_fraction	lower_threshold	lift	cumulative_lift	response_rate	score	cumulative_response_rate	cumulative_score	capture_rate	cumulative_capture_rate	gain	cumulative_gain	kolmogorov_smirnov
0	1	0.010037	9.999784e-01	1.130701	1.130701	1.000000	0.999990	1.000000	0.999990	0.011349	0.011349	13.070087	13.070087	0.011349
1	2	0.020015	9.999527e-01	1.130701	1.130701	1.000000	0.999965	1.000000	0.999977	0.011282	0.022631	13.070087	13.070087	0.022631
2	3	0.030016	9.999307e-01	1.130701	1.130701	1.000000	0.999941	1.000000	0.999965	0.011309	0.033939	13.070087	13.070087	0.033939
3	4	0.040064	9.999077e-01	1.130701	1.130701	1.000000	0.999919	1.000000	0.999954	0.011362	0.045301	13.070087	13.070087	0.045301
4	5	0.050042	9.998857e-01	1.130701	1.130701	1.000000	0.999897	1.000000	0.999942	0.011282	0.056583	13.070087	13.070087	0.056583
5	6	0.100014	9.997783e-01	1.130435	1.130568	0.999765	0.999832	0.999882	0.999887	0.056490	0.113073	13.043463	13.056784	0.112971
6	7	0.150021	9.996667e-01	1.129903	1.130346	0.999294	0.999724	0.999686	0.999833	0.056503	0.169576	12.990273	13.034614	0.169169
7	8	0.200005	9.995219e-01	1.129902	1.130235	0.999294	0.999598	0.999588	0.999774	0.056477	0.226052	12.990235	13.023523	0.225340
8	9	0.300007	9.991519e-01	1.130169	1.130213	0.999529	0.999352	0.999569	0.999633	0.113020	0.339072	13.016871	13.021306	0.337952
9	10	0.399998	9.985325e-01	1.128971	1.129903	0.998470	0.998869	0.999294	0.999442	0.112886	0.451958	12.897115	12.990261	0.449515
10	11	0.500000	9.974957e-01	1.128040	1.129530	0.997647	0.998054	0.998965	0.999165	0.112807	0.564765	12.804008	12.953009	0.560286
11	12	0.600002	9.948698e-01	1.121122	1.128129	0.991528	0.996408	0.997725	0.998705	0.112115	0.676880	12.112204	12.812872	0.665072
12	13	0.700217	9.867086e-01	1.108530	1.125324	0.980392	0.991512	0.995244	0.997676	0.111090	0.787970	10.853026	12.532382	0.759163
13	14	0.799995	9.519237e-01	1.078033	1.119425	0.953420	0.974366	0.990028	0.994768	0.107565	0.895535	7.803261	11.942546	0.826520
14	15	0.899998	3.969142e-01	0.919035	1.097159	0.812802	0.810172	0.970336	0.974257	0.091906	0.987441	-8.096463	9.715931	0.756476
15	16	1.000000	2.000000e-07	0.125589	1.000000	0.111072	0.065458	0.884407	0.883375	0.012559	1.000000	-87.441092	0.000000	0.000000


Cross-Validation Metrics Summary:
mean	sd	cv_1_valid	cv_2_valid	cv_3_valid	cv_4_valid	cv_5_valid	cv_6_valid	cv_7_valid	cv_8_valid	cv_9_valid	cv_10_valid
0	accuracy	0.975206	0.013885	0.968883	0.997476	0.990428	0.970082	0.980888	0.973927	0.967929	0.988183	0.953086	0.961181
1	auc	0.982331	0.013068	0.980003	0.984172	0.991780	0.957692	0.993523	0.986202	0.995128	0.989823	0.960702	0.984284
2	err	0.024794	0.013885	0.031117	0.002524	0.009572	0.029918	0.019112	0.026073	0.032071	0.011817	0.046915	0.038819
3	err_count	214.400000	131.342800	424.000000	20.000000	76.000000	238.000000	152.000000	206.000000	255.000000	93.000000	371.000000	309.000000
4	f0point5	0.983593	0.010713	0.987641	0.997959	0.993149	0.976375	0.985939	0.985787	0.976052	0.992632	0.961279	0.979123
5	f1	0.985646	0.008268	0.982644	0.998723	0.994906	0.984324	0.987496	0.985279	0.979490	0.993718	0.972517	0.977358
6	f2	0.987747	0.008062	0.977698	0.999489	0.996670	0.992403	0.989058	0.984773	0.982953	0.994807	0.984019	0.975599
7	lift_top_group	1.139865	0.099419	1.106186	1.012781	1.067491	1.062366	1.311943	1.128231	1.286570	1.065097	1.194923	1.163063
8	logloss	0.104632	0.045233	0.154014	0.064530	0.036066	0.110813	0.109466	0.089747	0.131627	0.047979	0.174882	0.127198
9	max_per_class_error	0.161805	0.123996	0.083333	0.200000	0.119522	0.475375	0.048652	0.108018	0.092603	0.124740	0.245736	0.120072
10	mcc	0.861594	0.072254	0.835270	0.893286	0.916842	0.689480	0.947023	0.871367	0.906322	0.894680	0.820062	0.841609
11	mean_per_class_accuracy	0.913685	0.059922	0.945547	0.900000	0.939164	0.761244	0.970725	0.938209	0.946336	0.935397	0.873052	0.927179
12	mean_per_class_error	0.086315	0.059922	0.054453	0.100000	0.060837	0.238756	0.029275	0.061791	0.053664	0.064603	0.126948	0.072821
13	mse	0.028119	0.013859	0.046913	0.012381	0.008280	0.026923	0.032368	0.022340	0.037709	0.012274	0.042767	0.039237
14	pr_auc	0.997537	0.002516	0.997754	0.999747	0.999271	0.996868	0.997617	0.998082	0.998596	0.999255	0.990893	0.997283
15	precision	0.982252	0.012990	0.991001	0.997450	0.991981	0.971146	0.984903	0.986125	0.973773	0.991909	0.953931	0.980303
16	r2	0.636789	0.257258	0.459388	0.006368	0.860205	0.512776	0.821407	0.778238	0.782187	0.786095	0.686727	0.674500
17	recall	0.989176	0.009362	0.974428	1.000000	0.997849	0.997863	0.990102	0.984435	0.985275	0.995534	0.991840	0.974430
18	rmse	0.162218	0.044778	0.216595	0.111271	0.090992	0.164084	0.179910	0.149466	0.194189	0.110790	0.206801	0.198084
19	specificity	0.838195	0.123996	0.916667	0.800000	0.880478	0.524625	0.951349	0.891982	0.907397	0.875260	0.754264	0.879928

Scoring History:
timestamp	duration	number_of_trees	training_rmse	training_logloss	training_auc	training_pr_auc	training_lift	training_classification_error
0		2022-01-17 13:49:05	38 min 7.994 sec	0.0	0.500000	0.693147	0.500000	0.884407	1.000000	0.115593
1		2022-01-17 13:49:11	38 min 14.367 sec	5.0	0.156851	0.150054	0.978892	0.994850	1.125187	0.014649
2		2022-01-17 13:49:16	38 min 19.044 sec	10.0	0.099000	0.060134	0.990638	0.997821	1.128543	0.009719
3		2022-01-17 13:49:21	38 min 23.768 sec	15.0	0.084446	0.036486	0.996459	0.999345	1.130170	0.007472
4		2022-01-17 13:49:26	38 min 28.584 sec	20.0	0.076988	0.027894	0.997945	0.999673	1.130701	0.006648
5		2022-01-17 13:49:30	38 min 33.446 sec	25.0	0.072344	0.023740	0.998567	0.999786	1.130701	0.005942
6		2022-01-17 13:49:35	38 min 38.468 sec	30.0	0.068293	0.020960	0.998833	0.999827	1.130701	0.005342
7		2022-01-17 13:49:41	38 min 43.601 sec	35.0	0.064755	0.018335	0.999157	0.999872	1.130701	0.004871
8		2022-01-17 13:49:46	38 min 48.800 sec	40.0	0.061130	0.016359	0.999295	0.999895	1.130701	0.004459
9		2022-01-17 13:49:51	38 min 54.130 sec	45.0	0.058160	0.014875	0.999446	0.999918	1.130701	0.003930
10		2022-01-17 13:49:56	38 min 59.526 sec	50.0	0.056357	0.013913	0.999527	0.999931	1.130701	0.003695
11		2022-01-17 13:50:02	39 min 5.100 sec	55.0	0.053535	0.012637	0.999622	0.999945	1.130701	0.003295
12		2022-01-17 13:50:08	39 min 10.763 sec	60.0	0.052413	0.012173	0.999652	0.999949	1.130701	0.003177
13		2022-01-17 13:50:10	39 min 13.431 sec	62.0	0.051663	0.011861	0.999674	0.999953	1.130701	0.003095

Variable Importances:
variable	relative_importance	scaled_importance	percentage
0	C4	26201.539062	1.000000	0.266395
1	C14.F	8755.258789	0.334151	0.089016
2	C1.F	8034.982422	0.306661	0.081693
3	C77.F	6546.078125	0.249836	0.066555
4	C19	5520.496582	0.210694	0.056128
5	C112	5408.960938	0.206437	0.054994
6	C23	4365.742676	0.166622	0.044387
7	C15	3193.223877	0.121872	0.032466
8	C74	3103.102539	0.118432	0.031550
9	C22	2181.500244	0.083258	0.022180
10	C80	1412.788452	0.053920	0.014364
11	C64	1384.787598	0.052851	0.014079
12	C71	1368.938477	0.052246	0.013918
13	C109	1163.791748	0.044417	0.011832
14	C70	1123.139648	0.042865	0.011419
15	C72.F	1114.068359	0.042519	0.011327
16	C153	1068.888794	0.040795	0.010868
17	C67.F	1036.211182	0.039548	0.010535
18	C30	999.634583	0.038152	0.010163
19	C21	882.519653	0.033682	0.008973

See the whole table with table.as_data_frame()


LEADERBOARD:
model_id	auc	logloss	aucpr	mean_per_class_error	rmse	mse
XGBoost_grid_1_AutoML_1_20220117_110208_model_3	0.976933	0.107981	0.996502	0.130971	0.171447	0.0293941
StackedEnsemble_BestOfFamily_7_AutoML_1_20220117_110208	0.976839	0.10374	0.996486	0.118572	0.163687	0.0267936
XGBoost_grid_1_AutoML_1_20220117_110208_model_2	0.976794	0.105375	0.996362	0.133867	0.168425	0.028367
XGBoost_1_AutoML_1_20220117_110208	0.976007	0.105265	0.996267	0.127801	0.166051	0.027573
StackedEnsemble_BestOfFamily_4_AutoML_1_20220117_110208	0.974903	0.105812	0.996168	0.121584	0.169769	0.0288215
XGBoost_2_AutoML_1_20220117_110208	0.97468	0.122082	0.996174	0.13139	0.183685	0.0337403
StackedEnsemble_AllModels_4_AutoML_1_20220117_110208	0.974505	0.110621	0.996157	0.124848	0.174347	0.0303968
XGBoost_grid_1_AutoML_1_20220117_110208_model_1	0.974449	0.115095	0.996133	0.132544	0.174998	0.0306244
StackedEnsemble_AllModels_7_AutoML_1_20220117_110208	0.973578	0.11263	0.995874	0.0910304	0.175158	0.0306802
StackedEnsemble_AllModels_3_AutoML_1_20220117_110208	0.973539	0.112591	0.995999	0.123785	0.176647	0.0312043
StackedEnsemble_BestOfFamily_3_AutoML_1_20220117_110208	0.973374	0.107718	0.995859	0.123185	0.171415	0.0293832
StackedEnsemble_BestOfFamily_5_AutoML_1_20220117_110208	0.973239	0.11432	0.995814	0.115931	0.175899	0.0309404
StackedEnsemble_AllModels_5_AutoML_1_20220117_110208	0.973036	0.112223	0.995556	0.102278	0.168932	0.028538
StackedEnsemble_BestOfFamily_6_AutoML_1_20220117_110208	0.972445	0.115741	0.995675	0.133267	0.177276	0.0314269
StackedEnsemble_AllModels_2_AutoML_1_20220117_110208	0.97212	0.110024	0.995671	0.122741	0.173113	0.0299681
GBM_3_AutoML_1_20220117_110208	0.971009	0.108854	0.995395	0.120121	0.168673	0.0284504
GBM_grid_1_AutoML_1_20220117_110208_model_1	0.971	0.106595	0.995406	0.112878	0.165035	0.0272365
StackedEnsemble_AllModels_6_AutoML_1_20220117_110208	0.970574	0.110994	0.99488	0.110451	0.169998	0.0288993
StackedEnsemble_BestOfFamily_1_AutoML_1_20220117_110208	0.970309	0.114295	0.995385	0.13363	0.175923	0.0309489
GBM_1_AutoML_1_20220117_110208	0.970195	0.10981	0.995316	0.130867	0.167783	0.028151
StackedEnsemble_BestOfFamily_2_AutoML_1_20220117_110208	0.970009	0.116699	0.995247	0.14138	0.179958	0.032385
GBM_4_AutoML_1_20220117_110208	0.969387	0.1135	0.994913	0.118907	0.17287	0.0298839
StackedEnsemble_AllModels_1_AutoML_1_20220117_110208	0.968733	0.119111	0.995091	0.14102	0.181329	0.0328803
GBM_2_AutoML_1_20220117_110208	0.968186	0.117319	0.994857	0.133317	0.178381	0.0318199
GBM_grid_1_AutoML_1_20220117_110208_model_2	0.967413	0.11374	0.994808	0.117655	0.172415	0.0297268
XGBoost_3_AutoML_1_20220117_110208	0.967089	0.121298	0.994864	0.140303	0.180202	0.0324726
DeepLearning_1_AutoML_1_20220117_110208	0.963716	0.134868	0.993856	0.132489	0.183182	0.0335557
DRF_1_AutoML_1_20220117_110208	0.962221	0.13273	0.991557	0.100691	0.183227	0.0335722
XRT_1_AutoML_1_20220117_110208	0.960838	0.143146	0.991988	0.150104	0.194738	0.037923
DeepLearning_grid_2_AutoML_1_20220117_110208_model_1	0.953436	0.313366	0.991169	0.134669	0.209459	0.0438729
GBM_5_AutoML_1_20220117_110208	0.952644	0.174596	0.992555	0.183511	0.23134	0.053518
DeepLearning_grid_3_AutoML_1_20220117_110208_model_1	0.947893	0.255943	0.988902	0.146023	0.20498	0.0420167
DeepLearning_grid_1_AutoML_1_20220117_110208_model_1	0.942486	0.394788	0.988642	0.143713	0.211209	0.0446091
GLM_1_AutoML_1_20220117_110208	0.882287	0.207451	0.979399	0.255602	0.236163	0.0557732
