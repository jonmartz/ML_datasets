AutoML progress: |
20:12:36.418: Fold column FOLD will be used for cross-validation. nfolds parameter will be ignored.
20:12:36.558: _train param, Dropping bad and constant columns: [C99, C98, C19, C107, C106, C139, C138, C103, C102, C124, C123, C122, C151, C150, C91, C90, C95, C94]

█████████████████████████████████████████████████████████
20:29:34.890: _train param, Dropping bad and constant columns: [C99, C98, C19, C107, C106, C139, C138, C103, C102, C124, C123, C122, C151, C150, C91, C90, C95, C94]

█████
20:54:00.219: _train param, Dropping bad and constant columns: [C99, C98, C19, C107, C106, C139, C138, C103, C102, C124, C123, C122, C151, C150, C91, C90, C95, C94]


21:13:30.489: _train param, Dropping unused columns: [C99, C98, C19, C107, C106, C139, C138, C103, C102, C124, C123, C122, C151, C150, C91, C90, C95, C94]

█
21:13:43.500: _train param, Dropping bad and constant columns: [C99, C98, C19, C107, C106, C139, C138, C103, C102, C124, C123, C122, C151, C150, C91, C90, C95, C94]


21:28:05.753: _train param, Dropping bad and constant columns: [C99, C98, C19, C107, C106, C139, C138, C103, C102, C124, C123, C122, C151, C150, C91, C90, C95, C94]


21:35:11.839: _train param, Dropping bad and constant columns: [C99, C98, C19, C107, C106, C139, C138, C103, C102, C124, C123, C122, C151, C150, C91, C90, C95, C94]


21:45:28.975: _train param, Dropping bad and constant columns: [C99, C98, C19, C107, C106, C139, C138, C103, C102, C124, C123, C122, C151, C150, C91, C90, C95, C94]


21:54:35.96: _train param, Dropping bad and constant columns: [C99, C98, C19, C107, C106, C139, C138, C103, C102, C124, C123, C122, C151, C150, C91, C90, C95, C94]


22:06:50.267: _train param, Dropping unused columns: [C99, C98, C19, C107, C106, C139, C138, C103, C102, C124, C123, C122, C151, C150, C91, C90, C95, C94]


22:07:02.279: _train param, Dropping unused columns: [C99, C98, C19, C107, C106, C139, C138, C103, C102, C124, C123, C122, C151, C150, C91, C90, C95, C94]


22:07:17.293: _train param, Dropping bad and constant columns: [C99, C98, C19, C107, C106, C139, C138, C103, C102, C124, C123, C122, C151, C150, C91, C90, C95, C94]


22:16:33.403: _train param, Dropping bad and constant columns: [C99, C98, C19, C107, C106, C139, C138, C103, C102, C124, C123, C122, C151, C150, C91, C90, C95, C94]


22:24:05.515: _train param, Dropping bad and constant columns: [C99, C98, C19, C107, C106, C139, C138, C103, C102, C124, C123, C122, C151, C150, C91, C90, C95, C94]


22:31:52.697: _train param, Dropping bad and constant columns: [C99, C98, C19, C107, C106, C139, C138, C103, C102, C124, C123, C122, C151, C150, C91, C90, C95, C94]


22:37:51.792: _train param, Dropping unused columns: [C99, C98, C19, C107, C106, C139, C138, C103, C102, C124, C123, C122, C151, C150, C91, C90, C95, C94]


22:38:05.812: _train param, Dropping unused columns: [C99, C98, C19, C107, C106, C139, C138, C103, C102, C124, C123, C122, C151, C150, C91, C90, C95, C94]


23:52:04.23: _train param, Dropping unused columns: [C99, C98, C19, C107, C106, C139, C138, C103, C102, C124, C123, C122, C151, C150, C91, C90, C95, C94]


23:52:17.42: _train param, Dropping unused columns: [C99, C98, C19, C107, C106, C139, C138, C103, C102, C124, C123, C122, C151, C150, C91, C90, C95, C94]


00:29:33.545: _train param, Dropping unused columns: [C99, C98, C19, C107, C106, C139, C138, C103, C102, C124, C123, C122, C151, C150, C91, C90, C95, C94]


00:30:01.574: _train param, Dropping unused columns: [C99, C98, C19, C107, C106, C139, C138, C103, C102, C124, C123, C122, C151, C150, C91, C90, C95, C94]


00:31:18.609: _train param, Dropping unused columns: [C99, C98, C19, C107, C106, C139, C138, C103, C102, C124, C123, C122, C151, C150, C91, C90, C95, C94]


00:32:18.660: _train param, Dropping unused columns: [C99, C98, C19, C107, C106, C139, C138, C103, C102, C124, C123, C122, C151, C150, C91, C90, C95, C94]


00:35:00.739: _train param, Dropping unused columns: [C99, C98, C19, C107, C106, C139, C138, C103, C102, C124, C123, C122, C151, C150, C91, C90, C95, C94]


00:37:00.793: _train param, Dropping unused columns: [C99, C98, C19, C107, C106, C139, C138, C103, C102, C124, C123, C122, C151, C150, C91, C90, C95, C94]


00:39:05.855: _train param, Dropping unused columns: [C99, C98, C19, C107, C106, C139, C138, C103, C102, C124, C123, C122, C151, C150, C91, C90, C95, C94]

| (done) 100%
Model Details
=============
H2OXGBoostEstimator :  XGBoost
Model Key:  XGBoost_3_AutoML_1_20220106_201236


Model Summary:
number_of_trees
0		59.0


ModelMetricsBinomial: xgboost
** Reported on train data. **

MSE: 0.0031363121265691666
RMSE: 0.05600278677502725
LogLoss: 0.013750864849123464
Mean Per-Class Error: 0.011876905745808804
AUC: 0.9995218939166879
AUCPR: 0.9999444665705544
Gini: 0.9990437878333758

Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5789159461855888:
Confirmed	Rejected	Error	Rate
0	Confirmed	9873.0	225.0	0.0223	(225.0/10098.0)
1	Rejected	134.0	90888.0	0.0015	(134.0/91022.0)
2	Total	10007.0	91113.0	0.0036	(359.0/101120.0)

Maximum Metrics: Maximum metrics at their respective thresholds
metric	threshold	value	idx
0	max f1	0.578916	0.998029	205.0
1	max f2	0.366019	0.998702	254.0
2	max f0point5	0.732597	0.998139	168.0
3	max accuracy	0.584747	0.996450	203.0
4	max precision	0.999911	1.000000	0.0
5	max recall	0.006465	1.000000	385.0
6	max specificity	0.999911	1.000000	0.0
7	max absolute_mcc	0.584747	0.980194	203.0
8	max min_per_class_accuracy	0.893886	0.991682	115.0
9	max mean_per_class_accuracy	0.868894	0.992072	125.0
10	max tns	0.999911	10098.000000	0.0
11	max fns	0.999911	80260.000000	0.0
12	max fps	0.000094	10098.000000	399.0
13	max tps	0.006465	91022.000000	385.0
14	max tnr	0.999911	1.000000	0.0
15	max fnr	0.999911	0.881765	0.0
16	max fpr	0.000094	1.000000	399.0
17	max tpr	0.006465	1.000000	385.0

Gains/Lift Table: Avg response rate: 90.01 %, avg score: 90.01 %
group	cumulative_data_fraction	lower_threshold	lift	cumulative_lift	response_rate	score	cumulative_response_rate	cumulative_score	capture_rate	cumulative_capture_rate	gain	cumulative_gain	kolmogorov_smirnov
0	1	0.010057	9.999530e-01	1.110940	1.110940	1.000000	0.999963	1.000000	0.999963	0.011173	0.011173	11.094021	11.094021	0.011173
1	2	0.020026	9.999413e-01	1.110940	1.110940	1.000000	0.999947	1.000000	0.999955	0.011074	0.022247	11.094021	11.094021	0.022247
2	3	0.030063	9.999313e-01	1.110940	1.110940	1.000000	0.999936	1.000000	0.999949	0.011151	0.033399	11.094021	11.094021	0.033399
3	4	0.040012	9.999233e-01	1.110940	1.110940	1.000000	0.999927	1.000000	0.999943	0.011052	0.044451	11.094021	11.094021	0.044451
4	5	0.050000	9.999147e-01	1.110940	1.110940	1.000000	0.999919	1.000000	0.999938	0.011096	0.055547	11.094021	11.094021	0.055547
5	6	0.100000	9.998741e-01	1.110940	1.110940	1.000000	0.999894	1.000000	0.999916	0.055547	0.111094	11.094021	11.094021	0.111094
6	7	0.150119	9.998337e-01	1.110940	1.110940	1.000000	0.999854	1.000000	0.999896	0.055679	0.166773	11.094021	11.094021	0.166773
7	8	0.200089	9.997830e-01	1.110940	1.110940	1.000000	0.999810	1.000000	0.999874	0.055514	0.222287	11.094021	11.094021	0.222287
8	9	0.300000	9.996750e-01	1.110940	1.110940	1.000000	0.999735	1.000000	0.999828	0.110995	0.333282	11.094021	11.094021	0.333282
9	10	0.400020	9.994972e-01	1.110940	1.110940	1.000000	0.999597	1.000000	0.999770	0.111116	0.444398	11.094021	11.094021	0.444398
10	11	0.500148	9.991753e-01	1.110940	1.110940	1.000000	0.999350	1.000000	0.999686	0.111237	0.555635	11.094021	11.094021	0.555635
11	12	0.600010	9.986633e-01	1.110940	1.110940	1.000000	0.998945	1.000000	0.999563	0.110940	0.666575	11.094021	11.094021	0.666575
12	13	0.700000	9.977085e-01	1.110830	1.110925	0.999901	0.998260	0.999986	0.999377	0.111072	0.777647	11.083034	11.092452	0.777548
13	14	0.800000	9.946829e-01	1.110061	1.110817	0.999209	0.996590	0.999889	0.999028	0.111006	0.888653	11.006130	11.081662	0.887762
14	15	0.900010	6.562921e-01	1.091716	1.108694	0.982696	0.970034	0.997978	0.995806	0.109182	0.997836	9.171599	10.869414	0.979614
15	16	1.000000	5.288440e-08	0.021645	1.000000	0.019484	0.038854	0.900138	0.900121	0.002164	1.000000	-97.835474	0.000000	0.000000


ModelMetricsBinomial: xgboost
** Reported on cross-validation data. **

MSE: 0.024904350601644684
RMSE: 0.1578111231873238
LogLoss: 0.09473463309868926
Mean Per-Class Error: 0.11904927587561522
AUC: 0.9799433798211729
AUCPR: 0.9974004936184436
Gini: 0.9598867596423457

Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.29729864120483396:
Confirmed	Rejected	Error	Rate
0	Confirmed	7775.0	2323.0	0.23	(2323.0/10098.0)
1	Rejected	733.0	90289.0	0.0081	(733.0/91022.0)
2	Total	8508.0	92612.0	0.0302	(3056.0/101120.0)

Maximum Metrics: Maximum metrics at their respective thresholds
metric	threshold	value	idx
0	max f1	0.297299	0.983358	290.0
1	max f2	0.104375	0.989667	341.0
2	max f0point5	0.740080	0.982314	173.0
3	max accuracy	0.374435	0.969778	272.0
4	max precision	0.999851	1.000000	0.0
5	max recall	0.000224	1.000000	399.0
6	max specificity	0.999851	1.000000	0.0
7	max absolute_mcc	0.405424	0.824693	264.0
8	max min_per_class_accuracy	0.944658	0.926421	77.0
9	max mean_per_class_accuracy	0.918376	0.928705	94.0
10	max tns	0.999851	10098.000000	0.0
11	max fns	0.999851	83644.000000	0.0
12	max fps	0.000224	10098.000000	399.0
13	max tps	0.000224	91022.000000	399.0
14	max tnr	0.999851	1.000000	0.0
15	max fnr	0.999851	0.918943	0.0
16	max fpr	0.000224	1.000000	399.0
17	max tpr	0.000224	1.000000	399.0

Gains/Lift Table: Avg response rate: 90.01 %, avg score: 89.76 %
group	cumulative_data_fraction	lower_threshold	lift	cumulative_lift	response_rate	score	cumulative_response_rate	cumulative_score	capture_rate	cumulative_capture_rate	gain	cumulative_gain	kolmogorov_smirnov
0	1	0.010008	0.999934	1.110940	1.110940	1.000000	0.999955	1.000000	0.999955	0.011118	0.011118	11.094021	11.094021	0.011118
1	2	0.020065	0.999904	1.110940	1.110940	1.000000	0.999919	1.000000	0.999937	0.011173	0.022291	11.094021	11.094021	0.022291
2	3	0.030014	0.999876	1.110940	1.110940	1.000000	0.999890	1.000000	0.999922	0.011052	0.033344	11.094021	11.094021	0.033344
3	4	0.040022	0.999849	1.110940	1.110940	1.000000	0.999863	1.000000	0.999907	0.011118	0.044462	11.094021	11.094021	0.044462
4	5	0.050020	0.999820	1.110940	1.110940	1.000000	0.999834	1.000000	0.999892	0.011107	0.055569	11.094021	11.094021	0.055569
5	6	0.100059	0.999701	1.110721	1.110830	0.999802	0.999761	0.999901	0.999827	0.055580	0.111149	11.072066	11.083041	0.111050
6	7	0.150010	0.999562	1.110940	1.110867	1.000000	0.999635	0.999934	0.999763	0.055492	0.166641	11.094021	11.086697	0.166542
7	8	0.200020	0.999402	1.110061	1.110666	0.999209	0.999482	0.999753	0.999693	0.055514	0.222155	11.006148	11.066558	0.221660
8	9	0.301384	0.999052	1.109531	1.110284	0.998732	0.999222	0.999409	0.999534	0.112467	0.334622	10.953121	11.028406	0.332840
9	10	0.400000	0.998498	1.109826	1.110171	0.998997	0.998794	0.999308	0.999352	0.109446	0.444068	10.982615	11.017117	0.441296
10	11	0.500000	0.997605	1.107205	1.109578	0.996638	0.998088	0.998774	0.999099	0.110720	0.554789	10.720485	10.957790	0.548649
11	12	0.600010	0.996364	1.107535	1.109237	0.996935	0.997030	0.998467	0.998754	0.110764	0.665553	10.753478	10.923736	0.656344
12	13	0.700138	0.992872	1.096237	1.107378	0.986765	0.994877	0.996794	0.998200	0.109765	0.775318	9.623740	10.737820	0.752838
13	14	0.800000	0.976533	1.084096	1.104472	0.975837	0.987245	0.994178	0.996832	0.108260	0.883578	8.409634	10.447200	0.836935
14	15	0.900267	0.628206	0.978469	1.090438	0.880757	0.891718	0.981546	0.985125	0.098108	0.981686	-2.153111	9.043843	0.815316
15	16	1.000000	0.000001	0.183633	1.000000	0.165295	0.108008	0.900138	0.897648	0.018314	1.000000	-81.636715	0.000000	0.000000


Cross-Validation Metrics Summary:
mean	sd	cv_1_valid	cv_2_valid	cv_3_valid	cv_4_valid	cv_5_valid	cv_6_valid	cv_7_valid	cv_8_valid	cv_9_valid	cv_10_valid
0	accuracy	0.977217	0.014063	0.986549	0.969250	0.989382	0.990581	0.967674	0.980611	0.984031	0.945782	0.988047	0.970261
1	auc	0.981853	0.018453	0.985515	0.985165	0.984386	0.997489	0.933636	0.971842	0.993181	0.982851	0.995357	0.989105
2	err	0.022783	0.014063	0.013452	0.030750	0.010618	0.009419	0.032326	0.019389	0.015969	0.054218	0.011953	0.029739
3	err_count	227.400000	137.486330	217.000000	419.000000	95.000000	84.000000	291.000000	172.000000	143.000000	482.000000	106.000000	265.000000
4	f0point5	0.984486	0.012970	0.991071	0.987966	0.993461	0.993489	0.973880	0.985847	0.992102	0.952569	0.993972	0.980499
5	f1	0.986640	0.010058	0.993182	0.982845	0.994525	0.994368	0.982817	0.989783	0.990845	0.961661	0.993688	0.982690
6	f2	0.988840	0.008447	0.995302	0.977777	0.995593	0.995249	0.991919	0.993750	0.989590	0.970928	0.993404	0.984890
7	lift_top_group	1.129081	0.123421	1.017278	1.106186	1.033022	1.197529	1.070328	1.060998	1.144263	1.437116	1.055589	1.168502
8	logloss	0.094123	0.059745	0.061500	0.156802	0.038336	0.048179	0.142376	0.064775	0.061024	0.208750	0.034627	0.124858
9	max_per_class_error	0.203564	0.182095	0.602190	0.079511	0.220280	0.036030	0.414157	0.278431	0.048716	0.126109	0.104925	0.125292
10	mcc	0.823799	0.126606	0.512863	0.837644	0.820376	0.965641	0.736327	0.807359	0.928555	0.870474	0.881198	0.877555
11	mean_per_class_accuracy	0.893384	0.088966	0.697266	0.947458	0.888013	0.979904	0.791962	0.858990	0.970020	0.925549	0.944145	0.930535
12	mean_per_class_error	0.106616	0.088966	0.302734	0.052542	0.111987	0.020096	0.208038	0.141010	0.029980	0.074451	0.055855	0.069465
13	mse	0.024657	0.015592	0.015440	0.044063	0.009490	0.012661	0.032046	0.016321	0.016540	0.052662	0.009955	0.037394
14	pr_auc	0.997582	0.002853	0.999724	0.998397	0.999378	0.999380	0.992863	0.997733	0.998926	0.991841	0.999682	0.997898
15	precision	0.983074	0.015264	0.989669	0.991410	0.992752	0.992904	0.968012	0.983241	0.992942	0.946602	0.994162	0.979045
16	r2	0.649716	0.239279	0.075257	0.492235	0.693317	0.908080	0.530954	0.698797	0.849885	0.751181	0.800462	0.696989
17	recall	0.990332	0.008535	0.996721	0.974428	0.996305	0.995837	0.998081	0.996412	0.988755	0.977207	0.993215	0.986362
18	rmse	0.150211	0.048232	0.124257	0.209912	0.097417	0.112521	0.179013	0.127753	0.128607	0.229482	0.099773	0.193376
19	specificity	0.796436	0.182095	0.397810	0.920489	0.779720	0.963970	0.585843	0.721569	0.951284	0.873891	0.895075	0.874708

Scoring History:
timestamp	duration	number_of_trees	training_rmse	training_logloss	training_auc	training_pr_auc	training_lift	training_classification_error
0		2022-01-06 22:15:45	8 min 27.914 sec	0.0	0.500000	0.693147	0.500000	0.900138	1.000000	0.099862
1		2022-01-06 22:15:50	8 min 33.675 sec	5.0	0.159390	0.152595	0.954046	0.989973	1.099874	0.016545
2		2022-01-06 22:15:54	8 min 37.364 sec	10.0	0.106111	0.064645	0.987510	0.997497	1.108488	0.011254
3		2022-01-06 22:15:58	8 min 41.090 sec	15.0	0.090417	0.039099	0.996334	0.999523	1.110940	0.009276
4		2022-01-06 22:16:02	8 min 44.845 sec	20.0	0.083108	0.030490	0.997505	0.999680	1.110940	0.007971
5		2022-01-06 22:16:05	8 min 48.658 sec	25.0	0.077318	0.025705	0.998272	0.999785	1.110940	0.006833
6		2022-01-06 22:16:09	8 min 52.421 sec	30.0	0.072324	0.022386	0.998605	0.999828	1.110940	0.006201
7		2022-01-06 22:16:13	8 min 56.313 sec	35.0	0.068090	0.019916	0.998917	0.999868	1.110940	0.005538
8		2022-01-06 22:16:17	9 min 0.183 sec	40.0	0.065849	0.018525	0.999054	0.999885	1.110940	0.005192
9		2022-01-06 22:16:21	9 min 4.071 sec	45.0	0.062458	0.016769	0.999212	0.999905	1.110940	0.004687
10		2022-01-06 22:16:25	9 min 8.032 sec	50.0	0.060099	0.015576	0.999375	0.999926	1.110940	0.004223
11		2022-01-06 22:16:29	9 min 11.939 sec	55.0	0.057845	0.014606	0.999440	0.999934	1.110940	0.003807
12		2022-01-06 22:16:32	9 min 15.204 sec	59.0	0.056003	0.013751	0.999522	0.999944	1.110940	0.003550

Variable Importances:
variable	relative_importance	scaled_importance	percentage
0	C1	18539.072266	1.000000	0.219952
1	C5	13995.462891	0.754917	0.166046
2	C2.F	7003.104492	0.377748	0.083087
3	C15.F	6352.145508	0.342636	0.075364
4	C24	3012.726318	0.162507	0.035744
5	C78.T	2134.685791	0.115145	0.025326
6	C16	2082.791016	0.112346	0.024711
7	C166.T	1786.296875	0.096353	0.021193
8	C23	1704.681274	0.091951	0.020225
9	C126	1693.739502	0.091361	0.020095
10	C72	1690.213013	0.091170	0.020053
11	C166.F	1535.440552	0.082822	0.018217
12	C20	1485.630859	0.080135	0.017626
13	C31	1375.802734	0.074211	0.016323
14	C81	1218.442749	0.065723	0.014456
15	C78.F	1151.805908	0.062129	0.013665
16	C75	980.590637	0.052893	0.011634
17	C14	920.652588	0.049660	0.010923
18	C7	696.686462	0.037579	0.008266
19	C15.T	662.994446	0.035762	0.007866

See the whole table with table.as_data_frame()


LEADERBOARD:
model_id	auc	logloss	aucpr	mean_per_class_error	rmse	mse
XGBoost_3_AutoML_1_20220106_201236	0.979943	0.0947346	0.9974	0.119049	0.157811	0.0249044
XGBoost_grid_1_AutoML_1_20220106_201236_model_2	0.978739	0.0949466	0.997199	0.100745	0.158318	0.0250647
XGBoost_1_AutoML_1_20220106_201236	0.97859	0.093472	0.997146	0.108827	0.155331	0.0241277
XGBoost_grid_1_AutoML_1_20220106_201236_model_1	0.977068	0.0978754	0.996937	0.120953	0.159399	0.0254082
XGBoost_grid_1_AutoML_1_20220106_201236_model_3	0.976095	0.0972777	0.996802	0.124014	0.15796	0.0249513
StackedEnsemble_BestOfFamily_7_AutoML_1_20220106_201236	0.975876	0.105991	0.996872	0.109033	0.163857	0.0268491
XGBoost_2_AutoML_1_20220106_201236	0.975618	0.100004	0.996673	0.122889	0.159356	0.0253943
GBM_grid_1_AutoML_1_20220106_201236_model_1	0.975093	0.0894093	0.996692	0.102238	0.150324	0.0225974
StackedEnsemble_BestOfFamily_4_AutoML_1_20220106_201236	0.974194	0.103201	0.996647	0.148474	0.167078	0.0279151
StackedEnsemble_BestOfFamily_2_AutoML_1_20220106_201236	0.974175	0.0954671	0.996482	0.124958	0.158933	0.0252597
StackedEnsemble_BestOfFamily_1_AutoML_1_20220106_201236	0.97386	0.0980712	0.996443	0.129986	0.162097	0.0262753
StackedEnsemble_BestOfFamily_3_AutoML_1_20220106_201236	0.973599	0.104675	0.9965	0.142597	0.168918	0.0285332
StackedEnsemble_AllModels_2_AutoML_1_20220106_201236	0.973166	0.102411	0.996397	0.152887	0.166461	0.0277092
StackedEnsemble_AllModels_1_AutoML_1_20220106_201236	0.973124	0.0958224	0.996325	0.124342	0.158652	0.0251705
StackedEnsemble_AllModels_3_AutoML_1_20220106_201236	0.972945	0.107717	0.996453	0.127358	0.171472	0.0294027
StackedEnsemble_AllModels_5_AutoML_1_20220106_201236	0.972846	0.117894	0.996214	0.14078	0.177439	0.0314847
StackedEnsemble_AllModels_4_AutoML_1_20220106_201236	0.972549	0.10782	0.996386	0.130269	0.171705	0.0294825
GBM_2_AutoML_1_20220106_201236	0.971855	0.0941674	0.996037	0.121473	0.156319	0.0244357
StackedEnsemble_BestOfFamily_5_AutoML_1_20220106_201236	0.971156	0.116802	0.99598	0.113564	0.177937	0.0316617
StackedEnsemble_AllModels_6_AutoML_1_20220106_201236	0.970731	0.113143	0.99538	0.141904	0.176681	0.0312161
StackedEnsemble_BestOfFamily_6_AutoML_1_20220106_201236	0.970671	0.111606	0.995592	0.117889	0.174641	0.0304995
GBM_1_AutoML_1_20220106_201236	0.970216	0.100195	0.995881	0.126126	0.161201	0.0259859
GBM_grid_1_AutoML_1_20220106_201236_model_2	0.969005	0.0968134	0.995629	0.0985686	0.156285	0.024425
GBM_3_AutoML_1_20220106_201236	0.968126	0.0966282	0.995428	0.132586	0.157456	0.0247925
GBM_4_AutoML_1_20220106_201236	0.966773	0.0971766	0.99508	0.103694	0.15517	0.0240777
GBM_5_AutoML_1_20220106_201236	0.966698	0.0996315	0.995206	0.118706	0.156322	0.0244366
XRT_1_AutoML_1_20220106_201236	0.962247	0.129269	0.994024	0.132831	0.176887	0.031289
DRF_1_AutoML_1_20220106_201236	0.960391	0.12854	0.993059	0.112935	0.17755	0.0315239
DeepLearning_1_AutoML_1_20220106_201236	0.955764	0.166814	0.992836	0.112061	0.187689	0.0352271
DeepLearning_grid_3_AutoML_1_20220106_201236_model_1	0.954526	0.234055	0.992181	0.133507	0.188767	0.035633
StackedEnsemble_AllModels_7_AutoML_1_20220106_201236	0.946853	0.152441	0.991827	0.128368	0.200104	0.0400415
DeepLearning_grid_1_AutoML_1_20220106_201236_model_1	0.945896	0.367509	0.990996	0.154361	0.202483	0.0409995
DeepLearning_grid_2_AutoML_1_20220106_201236_model_1	0.942037	0.282028	0.989164	0.126279	0.1859	0.0345589
GLM_1_AutoML_1_20220106_201236	0.916855	0.167789	0.988277	0.241601	0.212173	0.0450173
